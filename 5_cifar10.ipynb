{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodozzz/neural-networks-tasks/blob/main/5_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwiwMWLx8tWl"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olv_2Zjg8tWr"
      },
      "source": [
        "batch_size = 32  # in each iteration, we consider 32 training examples at once\n",
        "num_epochs = 200  # we iterate 200 times over the entire training set\n",
        "kernel_size = 3  # we will use 3x3 kernels throughout\n",
        "kernel_size_1 = 2  # we will use 2x2 kernels throughout\n",
        "kernel_size_2 = 4  # we will use 4x4 kernels throughout\n",
        "pool_size = 2  # we will use 2x2 pooling throughout\n",
        "conv_depth_1 = 32  # we will initially have 32 kernels per conv. layer...\n",
        "conv_depth_2 = 64  # ...switching to 64 after the first pooling layer\n",
        "drop_prob_1 = 0.25  # dropout after pooling with probability 0.25\n",
        "drop_prob_2 = 0.5  # dropout in the dense layer with probability 0.5\n",
        "hidden_size = 512  # the dense layer will have 512 neurons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlic-El88tWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15039d1-4c01-4e69-89a3-5c0511c3a823"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UQGwfxRM8tWu",
        "outputId": "9aa347d9-ba22-4ba4-a9ae-530c2a3a87b3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_test[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v0PfDWO8tWw"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # fetch CIFAR-10 data\n",
        "\n",
        "num_train, depth, height, width = X_train.shape # there are 50000 training examples in CIFAR-10\n",
        "num_test = X_test.shape[0] # there are 10000 test examples in CIFAR-10\n",
        "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= np.max(X_train) # Normalise data to [0, 1] range\n",
        "X_test /= np.max(X_train) # Normalise data to [0, 1] range\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SadqVwEJ8tWy",
        "outputId": "207dc01e-4195-41ee-92ee-c3d2b8e3c55b"
      },
      "source": [
        "inp = Input(shape=(depth, height, width))  # N.B. depth goes first in Keras\n",
        "\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
        "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
        "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
        "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
        "\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
        "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
        "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
        "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
        "\n",
        "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
        "flat = Flatten()(drop_2)\n",
        "hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)  # To define a model, just specify its input and output layers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # using the cross-entropy loss function\n",
        "              optimizer='adam',  # using the Adam optimiser\n",
        "              metrics=['accuracy'])  # reporting the accuracy\n",
        "\n",
        "model.fit(X_train, Y_train,  # Train the model using the training set...\n",
        "          batch_size=batch_size, epochs=num_epochs,\n",
        "          verbose=1, validation_split=0.1)  # ...holding out 10% of the data for validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0443 - accuracy: 0.2153 - val_loss: 1.6790 - val_accuracy: 0.3692\n",
            "Epoch 2/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.7008 - accuracy: 0.3692 - val_loss: 1.5404 - val_accuracy: 0.4276\n",
            "Epoch 3/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.6192 - accuracy: 0.3949 - val_loss: 1.4601 - val_accuracy: 0.4592\n",
            "Epoch 4/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5545 - accuracy: 0.4259 - val_loss: 1.4286 - val_accuracy: 0.4776\n",
            "Epoch 5/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5204 - accuracy: 0.4386 - val_loss: 1.3953 - val_accuracy: 0.4886\n",
            "Epoch 6/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5065 - accuracy: 0.4497 - val_loss: 1.4029 - val_accuracy: 0.4814\n",
            "Epoch 7/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4754 - accuracy: 0.4630 - val_loss: 1.3612 - val_accuracy: 0.5040\n",
            "Epoch 8/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4488 - accuracy: 0.4694 - val_loss: 1.3664 - val_accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4371 - accuracy: 0.4771 - val_loss: 1.3363 - val_accuracy: 0.5128\n",
            "Epoch 10/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4109 - accuracy: 0.4858 - val_loss: 1.3188 - val_accuracy: 0.5140\n",
            "Epoch 11/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.4010 - accuracy: 0.4903 - val_loss: 1.3358 - val_accuracy: 0.5178\n",
            "Epoch 12/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3876 - accuracy: 0.4938 - val_loss: 1.3315 - val_accuracy: 0.5214\n",
            "Epoch 13/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3870 - accuracy: 0.4954 - val_loss: 1.3135 - val_accuracy: 0.5282\n",
            "Epoch 14/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3700 - accuracy: 0.5042 - val_loss: 1.3364 - val_accuracy: 0.5118\n",
            "Epoch 15/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3680 - accuracy: 0.5046 - val_loss: 1.3035 - val_accuracy: 0.5214\n",
            "Epoch 16/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3569 - accuracy: 0.5118 - val_loss: 1.3019 - val_accuracy: 0.5328\n",
            "Epoch 17/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3557 - accuracy: 0.5130 - val_loss: 1.2683 - val_accuracy: 0.5360\n",
            "Epoch 18/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3283 - accuracy: 0.5165 - val_loss: 1.2793 - val_accuracy: 0.5364\n",
            "Epoch 19/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3292 - accuracy: 0.5209 - val_loss: 1.2876 - val_accuracy: 0.5262\n",
            "Epoch 20/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3324 - accuracy: 0.5220 - val_loss: 1.2774 - val_accuracy: 0.5402\n",
            "Epoch 21/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3228 - accuracy: 0.5223 - val_loss: 1.3127 - val_accuracy: 0.5272\n",
            "Epoch 22/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3275 - accuracy: 0.5231 - val_loss: 1.2591 - val_accuracy: 0.5474\n",
            "Epoch 23/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3188 - accuracy: 0.5277 - val_loss: 1.2684 - val_accuracy: 0.5494\n",
            "Epoch 24/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3090 - accuracy: 0.5293 - val_loss: 1.2589 - val_accuracy: 0.5434\n",
            "Epoch 25/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3034 - accuracy: 0.5341 - val_loss: 1.2743 - val_accuracy: 0.5412\n",
            "Epoch 26/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3029 - accuracy: 0.5306 - val_loss: 1.2821 - val_accuracy: 0.5340\n",
            "Epoch 27/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2992 - accuracy: 0.5333 - val_loss: 1.2634 - val_accuracy: 0.5430\n",
            "Epoch 28/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.3013 - accuracy: 0.5280 - val_loss: 1.2574 - val_accuracy: 0.5470\n",
            "Epoch 29/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2944 - accuracy: 0.5377 - val_loss: 1.2482 - val_accuracy: 0.5554\n",
            "Epoch 30/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2878 - accuracy: 0.5377 - val_loss: 1.2449 - val_accuracy: 0.5498\n",
            "Epoch 31/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2796 - accuracy: 0.5398 - val_loss: 1.3034 - val_accuracy: 0.5444\n",
            "Epoch 32/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2782 - accuracy: 0.5440 - val_loss: 1.2535 - val_accuracy: 0.5552\n",
            "Epoch 33/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2788 - accuracy: 0.5455 - val_loss: 1.2397 - val_accuracy: 0.5522\n",
            "Epoch 34/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2632 - accuracy: 0.5490 - val_loss: 1.2372 - val_accuracy: 0.5574\n",
            "Epoch 35/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2621 - accuracy: 0.5510 - val_loss: 1.2534 - val_accuracy: 0.5538\n",
            "Epoch 36/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2621 - accuracy: 0.5465 - val_loss: 1.2239 - val_accuracy: 0.5618\n",
            "Epoch 37/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2706 - accuracy: 0.5418 - val_loss: 1.2278 - val_accuracy: 0.5590\n",
            "Epoch 38/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2624 - accuracy: 0.5440 - val_loss: 1.2670 - val_accuracy: 0.5442\n",
            "Epoch 39/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2662 - accuracy: 0.5467 - val_loss: 1.2574 - val_accuracy: 0.5538\n",
            "Epoch 40/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2405 - accuracy: 0.5553 - val_loss: 1.2339 - val_accuracy: 0.5632\n",
            "Epoch 41/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2488 - accuracy: 0.5485 - val_loss: 1.2467 - val_accuracy: 0.5636\n",
            "Epoch 42/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2547 - accuracy: 0.5496 - val_loss: 1.2328 - val_accuracy: 0.5646\n",
            "Epoch 43/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2519 - accuracy: 0.5519 - val_loss: 1.2367 - val_accuracy: 0.5608\n",
            "Epoch 44/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2414 - accuracy: 0.5570 - val_loss: 1.2561 - val_accuracy: 0.5482\n",
            "Epoch 45/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2498 - accuracy: 0.5558 - val_loss: 1.2375 - val_accuracy: 0.5630\n",
            "Epoch 46/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2507 - accuracy: 0.5533 - val_loss: 1.2587 - val_accuracy: 0.5496\n",
            "Epoch 47/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2391 - accuracy: 0.5556 - val_loss: 1.2447 - val_accuracy: 0.5640\n",
            "Epoch 48/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2468 - accuracy: 0.5534 - val_loss: 1.2575 - val_accuracy: 0.5522\n",
            "Epoch 49/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2354 - accuracy: 0.5623 - val_loss: 1.2420 - val_accuracy: 0.5526\n",
            "Epoch 50/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2413 - accuracy: 0.5550 - val_loss: 1.2299 - val_accuracy: 0.5592\n",
            "Epoch 51/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2288 - accuracy: 0.5608 - val_loss: 1.2383 - val_accuracy: 0.5634\n",
            "Epoch 52/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2276 - accuracy: 0.5656 - val_loss: 1.2525 - val_accuracy: 0.5510\n",
            "Epoch 53/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2201 - accuracy: 0.5622 - val_loss: 1.2368 - val_accuracy: 0.5598\n",
            "Epoch 54/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2296 - accuracy: 0.5618 - val_loss: 1.2404 - val_accuracy: 0.5618\n",
            "Epoch 55/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2275 - accuracy: 0.5627 - val_loss: 1.2175 - val_accuracy: 0.5664\n",
            "Epoch 56/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2346 - accuracy: 0.5557 - val_loss: 1.2213 - val_accuracy: 0.5640\n",
            "Epoch 57/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2377 - accuracy: 0.5572 - val_loss: 1.2250 - val_accuracy: 0.5650\n",
            "Epoch 58/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2105 - accuracy: 0.5644 - val_loss: 1.2242 - val_accuracy: 0.5602\n",
            "Epoch 59/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2220 - accuracy: 0.5606 - val_loss: 1.2315 - val_accuracy: 0.5594\n",
            "Epoch 60/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2225 - accuracy: 0.5651 - val_loss: 1.2299 - val_accuracy: 0.5608\n",
            "Epoch 61/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2209 - accuracy: 0.5639 - val_loss: 1.2266 - val_accuracy: 0.5692\n",
            "Epoch 62/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2162 - accuracy: 0.5651 - val_loss: 1.2148 - val_accuracy: 0.5664\n",
            "Epoch 63/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2231 - accuracy: 0.5620 - val_loss: 1.2269 - val_accuracy: 0.5708\n",
            "Epoch 64/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2057 - accuracy: 0.5712 - val_loss: 1.2505 - val_accuracy: 0.5578\n",
            "Epoch 65/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2074 - accuracy: 0.5682 - val_loss: 1.2512 - val_accuracy: 0.5580\n",
            "Epoch 66/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2184 - accuracy: 0.5676 - val_loss: 1.2161 - val_accuracy: 0.5622\n",
            "Epoch 67/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1957 - accuracy: 0.5752 - val_loss: 1.2233 - val_accuracy: 0.5692\n",
            "Epoch 68/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2152 - accuracy: 0.5712 - val_loss: 1.2080 - val_accuracy: 0.5624\n",
            "Epoch 69/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2172 - accuracy: 0.5653 - val_loss: 1.2356 - val_accuracy: 0.5598\n",
            "Epoch 70/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2029 - accuracy: 0.5675 - val_loss: 1.2425 - val_accuracy: 0.5600\n",
            "Epoch 71/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2014 - accuracy: 0.5701 - val_loss: 1.2393 - val_accuracy: 0.5576\n",
            "Epoch 72/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2055 - accuracy: 0.5684 - val_loss: 1.2367 - val_accuracy: 0.5696\n",
            "Epoch 73/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2040 - accuracy: 0.5673 - val_loss: 1.2356 - val_accuracy: 0.5670\n",
            "Epoch 74/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2060 - accuracy: 0.5718 - val_loss: 1.2547 - val_accuracy: 0.5572\n",
            "Epoch 75/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1932 - accuracy: 0.5745 - val_loss: 1.2137 - val_accuracy: 0.5670\n",
            "Epoch 76/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1958 - accuracy: 0.5744 - val_loss: 1.2309 - val_accuracy: 0.5652\n",
            "Epoch 77/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1918 - accuracy: 0.5768 - val_loss: 1.2316 - val_accuracy: 0.5610\n",
            "Epoch 78/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2081 - accuracy: 0.5702 - val_loss: 1.2196 - val_accuracy: 0.5734\n",
            "Epoch 79/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1897 - accuracy: 0.5795 - val_loss: 1.2276 - val_accuracy: 0.5628\n",
            "Epoch 80/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1916 - accuracy: 0.5792 - val_loss: 1.2280 - val_accuracy: 0.5608\n",
            "Epoch 81/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2063 - accuracy: 0.5707 - val_loss: 1.2467 - val_accuracy: 0.5640\n",
            "Epoch 82/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1932 - accuracy: 0.5749 - val_loss: 1.2439 - val_accuracy: 0.5636\n",
            "Epoch 83/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1968 - accuracy: 0.5732 - val_loss: 1.2315 - val_accuracy: 0.5658\n",
            "Epoch 84/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1725 - accuracy: 0.5833 - val_loss: 1.2202 - val_accuracy: 0.5630\n",
            "Epoch 85/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1950 - accuracy: 0.5698 - val_loss: 1.2037 - val_accuracy: 0.5806\n",
            "Epoch 86/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1891 - accuracy: 0.5762 - val_loss: 1.2168 - val_accuracy: 0.5702\n",
            "Epoch 87/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1888 - accuracy: 0.5705 - val_loss: 1.2262 - val_accuracy: 0.5624\n",
            "Epoch 88/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1911 - accuracy: 0.5780 - val_loss: 1.2164 - val_accuracy: 0.5680\n",
            "Epoch 89/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1919 - accuracy: 0.5738 - val_loss: 1.2145 - val_accuracy: 0.5700\n",
            "Epoch 90/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1866 - accuracy: 0.5794 - val_loss: 1.2118 - val_accuracy: 0.5702\n",
            "Epoch 91/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1823 - accuracy: 0.5776 - val_loss: 1.2321 - val_accuracy: 0.5664\n",
            "Epoch 92/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1940 - accuracy: 0.5773 - val_loss: 1.2409 - val_accuracy: 0.5682\n",
            "Epoch 93/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1852 - accuracy: 0.5788 - val_loss: 1.2214 - val_accuracy: 0.5686\n",
            "Epoch 94/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1796 - accuracy: 0.5803 - val_loss: 1.2371 - val_accuracy: 0.5568\n",
            "Epoch 95/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1745 - accuracy: 0.5824 - val_loss: 1.2329 - val_accuracy: 0.5578\n",
            "Epoch 96/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1824 - accuracy: 0.5772 - val_loss: 1.2173 - val_accuracy: 0.5618\n",
            "Epoch 97/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1866 - accuracy: 0.5777 - val_loss: 1.2097 - val_accuracy: 0.5700\n",
            "Epoch 98/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1789 - accuracy: 0.5802 - val_loss: 1.2317 - val_accuracy: 0.5644\n",
            "Epoch 99/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1751 - accuracy: 0.5819 - val_loss: 1.2162 - val_accuracy: 0.5660\n",
            "Epoch 100/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1795 - accuracy: 0.5751 - val_loss: 1.2020 - val_accuracy: 0.5698\n",
            "Epoch 101/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1637 - accuracy: 0.5855 - val_loss: 1.2223 - val_accuracy: 0.5598\n",
            "Epoch 102/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1837 - accuracy: 0.5785 - val_loss: 1.2293 - val_accuracy: 0.5630\n",
            "Epoch 103/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1745 - accuracy: 0.5836 - val_loss: 1.2066 - val_accuracy: 0.5630\n",
            "Epoch 104/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1720 - accuracy: 0.5855 - val_loss: 1.2315 - val_accuracy: 0.5566\n",
            "Epoch 105/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1876 - accuracy: 0.5757 - val_loss: 1.2486 - val_accuracy: 0.5616\n",
            "Epoch 106/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1714 - accuracy: 0.5828 - val_loss: 1.2351 - val_accuracy: 0.5644\n",
            "Epoch 107/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1765 - accuracy: 0.5829 - val_loss: 1.2206 - val_accuracy: 0.5656\n",
            "Epoch 108/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1696 - accuracy: 0.5819 - val_loss: 1.2417 - val_accuracy: 0.5570\n",
            "Epoch 109/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1763 - accuracy: 0.5830 - val_loss: 1.2216 - val_accuracy: 0.5690\n",
            "Epoch 110/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1756 - accuracy: 0.5818 - val_loss: 1.2124 - val_accuracy: 0.5670\n",
            "Epoch 111/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1680 - accuracy: 0.5846 - val_loss: 1.2102 - val_accuracy: 0.5726\n",
            "Epoch 112/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1624 - accuracy: 0.5838 - val_loss: 1.2299 - val_accuracy: 0.5634\n",
            "Epoch 113/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1781 - accuracy: 0.5823 - val_loss: 1.2184 - val_accuracy: 0.5676\n",
            "Epoch 114/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1695 - accuracy: 0.5814 - val_loss: 1.2141 - val_accuracy: 0.5602\n",
            "Epoch 115/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1739 - accuracy: 0.5796 - val_loss: 1.2085 - val_accuracy: 0.5684\n",
            "Epoch 116/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1769 - accuracy: 0.5812 - val_loss: 1.2187 - val_accuracy: 0.5792\n",
            "Epoch 117/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1710 - accuracy: 0.5824 - val_loss: 1.2114 - val_accuracy: 0.5670\n",
            "Epoch 118/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1712 - accuracy: 0.5831 - val_loss: 1.2388 - val_accuracy: 0.5612\n",
            "Epoch 119/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1612 - accuracy: 0.5897 - val_loss: 1.2087 - val_accuracy: 0.5684\n",
            "Epoch 120/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1749 - accuracy: 0.5852 - val_loss: 1.2262 - val_accuracy: 0.5616\n",
            "Epoch 121/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1708 - accuracy: 0.5822 - val_loss: 1.2307 - val_accuracy: 0.5684\n",
            "Epoch 122/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1699 - accuracy: 0.5828 - val_loss: 1.2117 - val_accuracy: 0.5736\n",
            "Epoch 123/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1584 - accuracy: 0.5896 - val_loss: 1.2277 - val_accuracy: 0.5666\n",
            "Epoch 124/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1693 - accuracy: 0.5828 - val_loss: 1.2117 - val_accuracy: 0.5622\n",
            "Epoch 125/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1835 - accuracy: 0.5801 - val_loss: 1.2196 - val_accuracy: 0.5694\n",
            "Epoch 126/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1684 - accuracy: 0.5885 - val_loss: 1.2130 - val_accuracy: 0.5664\n",
            "Epoch 127/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1636 - accuracy: 0.5869 - val_loss: 1.2167 - val_accuracy: 0.5578\n",
            "Epoch 128/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1601 - accuracy: 0.5856 - val_loss: 1.2118 - val_accuracy: 0.5668\n",
            "Epoch 129/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1632 - accuracy: 0.5865 - val_loss: 1.2216 - val_accuracy: 0.5664\n",
            "Epoch 130/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1651 - accuracy: 0.5864 - val_loss: 1.2279 - val_accuracy: 0.5646\n",
            "Epoch 131/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1656 - accuracy: 0.5831 - val_loss: 1.2179 - val_accuracy: 0.5690\n",
            "Epoch 132/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1629 - accuracy: 0.5892 - val_loss: 1.2290 - val_accuracy: 0.5672\n",
            "Epoch 133/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1710 - accuracy: 0.5854 - val_loss: 1.2046 - val_accuracy: 0.5786\n",
            "Epoch 134/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1579 - accuracy: 0.5851 - val_loss: 1.2217 - val_accuracy: 0.5748\n",
            "Epoch 135/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1580 - accuracy: 0.5893 - val_loss: 1.2140 - val_accuracy: 0.5706\n",
            "Epoch 136/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1585 - accuracy: 0.5918 - val_loss: 1.2171 - val_accuracy: 0.5592\n",
            "Epoch 137/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1646 - accuracy: 0.5846 - val_loss: 1.2135 - val_accuracy: 0.5792\n",
            "Epoch 138/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1641 - accuracy: 0.5862 - val_loss: 1.2014 - val_accuracy: 0.5740\n",
            "Epoch 139/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1589 - accuracy: 0.5887 - val_loss: 1.2314 - val_accuracy: 0.5708\n",
            "Epoch 140/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1545 - accuracy: 0.5890 - val_loss: 1.2459 - val_accuracy: 0.5546\n",
            "Epoch 141/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1643 - accuracy: 0.5866 - val_loss: 1.2200 - val_accuracy: 0.5660\n",
            "Epoch 142/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1551 - accuracy: 0.5893 - val_loss: 1.2214 - val_accuracy: 0.5702\n",
            "Epoch 143/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1499 - accuracy: 0.5925 - val_loss: 1.2260 - val_accuracy: 0.5570\n",
            "Epoch 144/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1573 - accuracy: 0.5914 - val_loss: 1.2047 - val_accuracy: 0.5698\n",
            "Epoch 145/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1602 - accuracy: 0.5868 - val_loss: 1.2259 - val_accuracy: 0.5658\n",
            "Epoch 146/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1539 - accuracy: 0.5906 - val_loss: 1.2277 - val_accuracy: 0.5614\n",
            "Epoch 147/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1646 - accuracy: 0.5887 - val_loss: 1.2167 - val_accuracy: 0.5722\n",
            "Epoch 148/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1584 - accuracy: 0.5878 - val_loss: 1.2157 - val_accuracy: 0.5672\n",
            "Epoch 149/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1604 - accuracy: 0.5877 - val_loss: 1.2374 - val_accuracy: 0.5630\n",
            "Epoch 150/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1517 - accuracy: 0.5890 - val_loss: 1.2078 - val_accuracy: 0.5738\n",
            "Epoch 151/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1540 - accuracy: 0.5921 - val_loss: 1.1984 - val_accuracy: 0.5804\n",
            "Epoch 152/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1617 - accuracy: 0.5872 - val_loss: 1.2002 - val_accuracy: 0.5772\n",
            "Epoch 153/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1517 - accuracy: 0.5915 - val_loss: 1.2195 - val_accuracy: 0.5686\n",
            "Epoch 154/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1502 - accuracy: 0.5911 - val_loss: 1.2192 - val_accuracy: 0.5670\n",
            "Epoch 155/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1597 - accuracy: 0.5873 - val_loss: 1.2239 - val_accuracy: 0.5524\n",
            "Epoch 156/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1567 - accuracy: 0.5893 - val_loss: 1.1984 - val_accuracy: 0.5704\n",
            "Epoch 157/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1502 - accuracy: 0.5948 - val_loss: 1.2231 - val_accuracy: 0.5600\n",
            "Epoch 158/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1639 - accuracy: 0.5870 - val_loss: 1.2120 - val_accuracy: 0.5638\n",
            "Epoch 159/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1617 - accuracy: 0.5892 - val_loss: 1.2220 - val_accuracy: 0.5620\n",
            "Epoch 160/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1663 - accuracy: 0.5901 - val_loss: 1.2004 - val_accuracy: 0.5706\n",
            "Epoch 161/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1506 - accuracy: 0.5919 - val_loss: 1.2007 - val_accuracy: 0.5678\n",
            "Epoch 162/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1600 - accuracy: 0.5862 - val_loss: 1.1998 - val_accuracy: 0.5708\n",
            "Epoch 163/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1475 - accuracy: 0.5950 - val_loss: 1.1972 - val_accuracy: 0.5742\n",
            "Epoch 164/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1572 - accuracy: 0.5916 - val_loss: 1.2078 - val_accuracy: 0.5714\n",
            "Epoch 165/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1584 - accuracy: 0.5875 - val_loss: 1.2295 - val_accuracy: 0.5588\n",
            "Epoch 166/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1553 - accuracy: 0.5927 - val_loss: 1.2106 - val_accuracy: 0.5728\n",
            "Epoch 167/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1678 - accuracy: 0.5869 - val_loss: 1.2267 - val_accuracy: 0.5632\n",
            "Epoch 168/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1580 - accuracy: 0.5888 - val_loss: 1.2140 - val_accuracy: 0.5694\n",
            "Epoch 169/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1610 - accuracy: 0.5936 - val_loss: 1.2184 - val_accuracy: 0.5638\n",
            "Epoch 170/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1609 - accuracy: 0.5905 - val_loss: 1.2114 - val_accuracy: 0.5730\n",
            "Epoch 171/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1447 - accuracy: 0.5937 - val_loss: 1.2267 - val_accuracy: 0.5582\n",
            "Epoch 172/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1467 - accuracy: 0.5930 - val_loss: 1.1998 - val_accuracy: 0.5746\n",
            "Epoch 173/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1580 - accuracy: 0.5875 - val_loss: 1.2115 - val_accuracy: 0.5752\n",
            "Epoch 174/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1564 - accuracy: 0.5910 - val_loss: 1.2308 - val_accuracy: 0.5630\n",
            "Epoch 175/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1573 - accuracy: 0.5877 - val_loss: 1.1940 - val_accuracy: 0.5686\n",
            "Epoch 176/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1466 - accuracy: 0.5931 - val_loss: 1.2217 - val_accuracy: 0.5628\n",
            "Epoch 177/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1521 - accuracy: 0.5931 - val_loss: 1.2144 - val_accuracy: 0.5728\n",
            "Epoch 178/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1426 - accuracy: 0.5955 - val_loss: 1.2020 - val_accuracy: 0.5716\n",
            "Epoch 179/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1508 - accuracy: 0.5961 - val_loss: 1.2244 - val_accuracy: 0.5678\n",
            "Epoch 180/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1483 - accuracy: 0.5955 - val_loss: 1.2200 - val_accuracy: 0.5696\n",
            "Epoch 181/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1531 - accuracy: 0.5930 - val_loss: 1.2139 - val_accuracy: 0.5732\n",
            "Epoch 182/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1409 - accuracy: 0.5944 - val_loss: 1.2012 - val_accuracy: 0.5764\n",
            "Epoch 183/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1440 - accuracy: 0.5961 - val_loss: 1.2080 - val_accuracy: 0.5680\n",
            "Epoch 184/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1512 - accuracy: 0.5951 - val_loss: 1.2129 - val_accuracy: 0.5682\n",
            "Epoch 185/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1515 - accuracy: 0.5951 - val_loss: 1.2109 - val_accuracy: 0.5746\n",
            "Epoch 186/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1450 - accuracy: 0.5971 - val_loss: 1.2432 - val_accuracy: 0.5618\n",
            "Epoch 187/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1403 - accuracy: 0.5974 - val_loss: 1.2496 - val_accuracy: 0.5568\n",
            "Epoch 188/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1561 - accuracy: 0.5916 - val_loss: 1.2039 - val_accuracy: 0.5694\n",
            "Epoch 189/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1431 - accuracy: 0.5976 - val_loss: 1.1976 - val_accuracy: 0.5788\n",
            "Epoch 190/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1509 - accuracy: 0.5920 - val_loss: 1.2056 - val_accuracy: 0.5644\n",
            "Epoch 191/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1474 - accuracy: 0.5955 - val_loss: 1.2231 - val_accuracy: 0.5632\n",
            "Epoch 192/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1549 - accuracy: 0.5927 - val_loss: 1.2210 - val_accuracy: 0.5660\n",
            "Epoch 193/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1429 - accuracy: 0.5966 - val_loss: 1.2033 - val_accuracy: 0.5714\n",
            "Epoch 194/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1461 - accuracy: 0.5918 - val_loss: 1.1942 - val_accuracy: 0.5692\n",
            "Epoch 195/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1441 - accuracy: 0.5935 - val_loss: 1.1900 - val_accuracy: 0.5774\n",
            "Epoch 196/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1541 - accuracy: 0.5934 - val_loss: 1.2049 - val_accuracy: 0.5718\n",
            "Epoch 197/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1433 - accuracy: 0.5956 - val_loss: 1.2018 - val_accuracy: 0.5778\n",
            "Epoch 198/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1459 - accuracy: 0.5934 - val_loss: 1.2189 - val_accuracy: 0.5650\n",
            "Epoch 199/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1522 - accuracy: 0.5977 - val_loss: 1.2071 - val_accuracy: 0.5686\n",
            "Epoch 200/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1407 - accuracy: 0.5955 - val_loss: 1.2108 - val_accuracy: 0.5722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0ca6f7f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yKZjff86noyv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jl-iECrno6F",
        "outputId": "d961a2c3-878f-4c7d-875e-550c37961d64"
      },
      "source": [
        "inp = Input(shape=(depth, height, width))  # N.B. depth goes first in Keras\n",
        "\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(inp)\n",
        "conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
        "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
        "\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(pool_1)\n",
        "conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
        "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
        "\n",
        "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
        "flat = Flatten()(pool_2)\n",
        "hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "out = Dense(num_classes, activation='softmax')(hidden)\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)  # To define a model, just specify its input and output layers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # using the cross-entropy loss function\n",
        "              optimizer='adam',  # using the Adam optimiser\n",
        "              metrics=['accuracy'])  # reporting the accuracy\n",
        "\n",
        "model.fit(X_train, Y_train,  # Train the model using the training set...\n",
        "          batch_size=batch_size, epochs=num_epochs,\n",
        "          verbose=1, validation_split=0.1)  # ...holding out 10% of the data for validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.9715 - accuracy: 0.2547 - val_loss: 1.6016 - val_accuracy: 0.3994\n",
            "Epoch 2/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.5928 - accuracy: 0.4019 - val_loss: 1.5126 - val_accuracy: 0.4450\n",
            "Epoch 3/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.4629 - accuracy: 0.4560 - val_loss: 1.4534 - val_accuracy: 0.4664\n",
            "Epoch 4/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.3909 - accuracy: 0.4866 - val_loss: 1.3915 - val_accuracy: 0.4952\n",
            "Epoch 5/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.3442 - accuracy: 0.5078 - val_loss: 1.3292 - val_accuracy: 0.5200\n",
            "Epoch 6/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.3034 - accuracy: 0.5255 - val_loss: 1.3472 - val_accuracy: 0.5050\n",
            "Epoch 7/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2753 - accuracy: 0.5341 - val_loss: 1.2814 - val_accuracy: 0.5396\n",
            "Epoch 8/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2412 - accuracy: 0.5480 - val_loss: 1.3477 - val_accuracy: 0.5142\n",
            "Epoch 9/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.2253 - accuracy: 0.5527 - val_loss: 1.2668 - val_accuracy: 0.5424\n",
            "Epoch 10/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1951 - accuracy: 0.5639 - val_loss: 1.2632 - val_accuracy: 0.5420\n",
            "Epoch 11/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1797 - accuracy: 0.5744 - val_loss: 1.2459 - val_accuracy: 0.5474\n",
            "Epoch 12/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1562 - accuracy: 0.5790 - val_loss: 1.2277 - val_accuracy: 0.5532\n",
            "Epoch 13/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1485 - accuracy: 0.5840 - val_loss: 1.2691 - val_accuracy: 0.5506\n",
            "Epoch 14/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1276 - accuracy: 0.5884 - val_loss: 1.2380 - val_accuracy: 0.5590\n",
            "Epoch 15/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.1219 - accuracy: 0.5929 - val_loss: 1.2324 - val_accuracy: 0.5566\n",
            "Epoch 16/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1091 - accuracy: 0.5982 - val_loss: 1.2295 - val_accuracy: 0.5592\n",
            "Epoch 17/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0823 - accuracy: 0.6035 - val_loss: 1.2200 - val_accuracy: 0.5582\n",
            "Epoch 18/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0692 - accuracy: 0.6145 - val_loss: 1.3117 - val_accuracy: 0.5372\n",
            "Epoch 19/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0682 - accuracy: 0.6117 - val_loss: 1.2273 - val_accuracy: 0.5568\n",
            "Epoch 20/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0479 - accuracy: 0.6202 - val_loss: 1.1906 - val_accuracy: 0.5780\n",
            "Epoch 21/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0334 - accuracy: 0.6245 - val_loss: 1.2599 - val_accuracy: 0.5540\n",
            "Epoch 22/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0301 - accuracy: 0.6244 - val_loss: 1.2007 - val_accuracy: 0.5696\n",
            "Epoch 23/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0170 - accuracy: 0.6325 - val_loss: 1.2562 - val_accuracy: 0.5620\n",
            "Epoch 24/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0115 - accuracy: 0.6335 - val_loss: 1.2301 - val_accuracy: 0.5612\n",
            "Epoch 25/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.0005 - accuracy: 0.6340 - val_loss: 1.2240 - val_accuracy: 0.5696\n",
            "Epoch 26/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9917 - accuracy: 0.6422 - val_loss: 1.2235 - val_accuracy: 0.5670\n",
            "Epoch 27/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9843 - accuracy: 0.6432 - val_loss: 1.2401 - val_accuracy: 0.5636\n",
            "Epoch 28/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9752 - accuracy: 0.6441 - val_loss: 1.2435 - val_accuracy: 0.5728\n",
            "Epoch 29/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9634 - accuracy: 0.6501 - val_loss: 1.2573 - val_accuracy: 0.5680\n",
            "Epoch 30/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9458 - accuracy: 0.6561 - val_loss: 1.2518 - val_accuracy: 0.5602\n",
            "Epoch 31/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9421 - accuracy: 0.6559 - val_loss: 1.2695 - val_accuracy: 0.5616\n",
            "Epoch 32/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.9339 - accuracy: 0.6567 - val_loss: 1.2580 - val_accuracy: 0.5686\n",
            "Epoch 33/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9225 - accuracy: 0.6625 - val_loss: 1.2743 - val_accuracy: 0.5646\n",
            "Epoch 34/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.9064 - accuracy: 0.6670 - val_loss: 1.2779 - val_accuracy: 0.5618\n",
            "Epoch 35/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8987 - accuracy: 0.6724 - val_loss: 1.2949 - val_accuracy: 0.5550\n",
            "Epoch 36/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8996 - accuracy: 0.6680 - val_loss: 1.3624 - val_accuracy: 0.5412\n",
            "Epoch 37/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8844 - accuracy: 0.6724 - val_loss: 1.2967 - val_accuracy: 0.5636\n",
            "Epoch 38/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8820 - accuracy: 0.6751 - val_loss: 1.2989 - val_accuracy: 0.5714\n",
            "Epoch 39/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8633 - accuracy: 0.6804 - val_loss: 1.3200 - val_accuracy: 0.5702\n",
            "Epoch 40/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8554 - accuracy: 0.6854 - val_loss: 1.3018 - val_accuracy: 0.5740\n",
            "Epoch 41/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8588 - accuracy: 0.6836 - val_loss: 1.3266 - val_accuracy: 0.5590\n",
            "Epoch 42/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8446 - accuracy: 0.6908 - val_loss: 1.3362 - val_accuracy: 0.5608\n",
            "Epoch 43/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8242 - accuracy: 0.6955 - val_loss: 1.3688 - val_accuracy: 0.5586\n",
            "Epoch 44/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8210 - accuracy: 0.6978 - val_loss: 1.3341 - val_accuracy: 0.5642\n",
            "Epoch 45/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.8166 - accuracy: 0.6987 - val_loss: 1.4177 - val_accuracy: 0.5634\n",
            "Epoch 46/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8025 - accuracy: 0.7038 - val_loss: 1.3870 - val_accuracy: 0.5598\n",
            "Epoch 47/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7989 - accuracy: 0.7061 - val_loss: 1.4219 - val_accuracy: 0.5576\n",
            "Epoch 48/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7880 - accuracy: 0.7116 - val_loss: 1.4039 - val_accuracy: 0.5624\n",
            "Epoch 49/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7814 - accuracy: 0.7130 - val_loss: 1.4344 - val_accuracy: 0.5580\n",
            "Epoch 50/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7724 - accuracy: 0.7139 - val_loss: 1.4398 - val_accuracy: 0.5598\n",
            "Epoch 51/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7605 - accuracy: 0.7194 - val_loss: 1.4739 - val_accuracy: 0.5556\n",
            "Epoch 52/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7594 - accuracy: 0.7206 - val_loss: 1.4272 - val_accuracy: 0.5572\n",
            "Epoch 53/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7423 - accuracy: 0.7236 - val_loss: 1.5219 - val_accuracy: 0.5478\n",
            "Epoch 54/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7382 - accuracy: 0.7240 - val_loss: 1.4761 - val_accuracy: 0.5622\n",
            "Epoch 55/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7377 - accuracy: 0.7280 - val_loss: 1.5066 - val_accuracy: 0.5532\n",
            "Epoch 56/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7214 - accuracy: 0.7321 - val_loss: 1.5436 - val_accuracy: 0.5492\n",
            "Epoch 57/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7267 - accuracy: 0.7261 - val_loss: 1.5735 - val_accuracy: 0.5548\n",
            "Epoch 58/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.7116 - accuracy: 0.7376 - val_loss: 1.5456 - val_accuracy: 0.5528\n",
            "Epoch 59/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7012 - accuracy: 0.7384 - val_loss: 1.6276 - val_accuracy: 0.5508\n",
            "Epoch 60/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6935 - accuracy: 0.7434 - val_loss: 1.5723 - val_accuracy: 0.5512\n",
            "Epoch 61/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6850 - accuracy: 0.7462 - val_loss: 1.6304 - val_accuracy: 0.5464\n",
            "Epoch 62/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6871 - accuracy: 0.7462 - val_loss: 1.6567 - val_accuracy: 0.5484\n",
            "Epoch 63/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6759 - accuracy: 0.7470 - val_loss: 1.6600 - val_accuracy: 0.5480\n",
            "Epoch 64/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6722 - accuracy: 0.7495 - val_loss: 1.6654 - val_accuracy: 0.5502\n",
            "Epoch 65/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6661 - accuracy: 0.7532 - val_loss: 1.7023 - val_accuracy: 0.5468\n",
            "Epoch 66/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6560 - accuracy: 0.7536 - val_loss: 1.7336 - val_accuracy: 0.5330\n",
            "Epoch 67/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6541 - accuracy: 0.7584 - val_loss: 1.7281 - val_accuracy: 0.5422\n",
            "Epoch 68/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6459 - accuracy: 0.7595 - val_loss: 1.8239 - val_accuracy: 0.5290\n",
            "Epoch 69/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6621 - accuracy: 0.7519 - val_loss: 1.7882 - val_accuracy: 0.5482\n",
            "Epoch 70/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6373 - accuracy: 0.7643 - val_loss: 1.7251 - val_accuracy: 0.5500\n",
            "Epoch 71/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6355 - accuracy: 0.7599 - val_loss: 1.8075 - val_accuracy: 0.5396\n",
            "Epoch 72/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6270 - accuracy: 0.7652 - val_loss: 1.8204 - val_accuracy: 0.5450\n",
            "Epoch 73/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6167 - accuracy: 0.7732 - val_loss: 1.8181 - val_accuracy: 0.5404\n",
            "Epoch 74/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6054 - accuracy: 0.7767 - val_loss: 1.8532 - val_accuracy: 0.5368\n",
            "Epoch 75/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6105 - accuracy: 0.7719 - val_loss: 1.8792 - val_accuracy: 0.5410\n",
            "Epoch 76/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6098 - accuracy: 0.7722 - val_loss: 1.8781 - val_accuracy: 0.5442\n",
            "Epoch 77/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6099 - accuracy: 0.7751 - val_loss: 1.9225 - val_accuracy: 0.5366\n",
            "Epoch 78/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5929 - accuracy: 0.7810 - val_loss: 1.9030 - val_accuracy: 0.5452\n",
            "Epoch 79/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.6001 - accuracy: 0.7741 - val_loss: 1.9013 - val_accuracy: 0.5338\n",
            "Epoch 80/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5935 - accuracy: 0.7777 - val_loss: 2.0319 - val_accuracy: 0.5322\n",
            "Epoch 81/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5919 - accuracy: 0.7804 - val_loss: 1.9773 - val_accuracy: 0.5376\n",
            "Epoch 82/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5817 - accuracy: 0.7848 - val_loss: 1.9887 - val_accuracy: 0.5416\n",
            "Epoch 83/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5864 - accuracy: 0.7819 - val_loss: 2.0374 - val_accuracy: 0.5244\n",
            "Epoch 84/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5807 - accuracy: 0.7821 - val_loss: 1.9911 - val_accuracy: 0.5418\n",
            "Epoch 85/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5772 - accuracy: 0.7812 - val_loss: 2.0537 - val_accuracy: 0.5312\n",
            "Epoch 86/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5679 - accuracy: 0.7877 - val_loss: 2.0537 - val_accuracy: 0.5312\n",
            "Epoch 87/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5598 - accuracy: 0.7905 - val_loss: 2.0620 - val_accuracy: 0.5278\n",
            "Epoch 88/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5461 - accuracy: 0.7961 - val_loss: 2.0991 - val_accuracy: 0.5290\n",
            "Epoch 89/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5561 - accuracy: 0.7921 - val_loss: 2.1737 - val_accuracy: 0.5332\n",
            "Epoch 90/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5453 - accuracy: 0.7969 - val_loss: 2.0675 - val_accuracy: 0.5328\n",
            "Epoch 91/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5592 - accuracy: 0.7890 - val_loss: 2.2322 - val_accuracy: 0.5300\n",
            "Epoch 92/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5492 - accuracy: 0.7955 - val_loss: 2.2002 - val_accuracy: 0.5276\n",
            "Epoch 93/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5402 - accuracy: 0.7974 - val_loss: 2.1786 - val_accuracy: 0.5230\n",
            "Epoch 94/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5474 - accuracy: 0.7928 - val_loss: 2.1754 - val_accuracy: 0.5328\n",
            "Epoch 95/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5328 - accuracy: 0.8010 - val_loss: 2.2449 - val_accuracy: 0.5270\n",
            "Epoch 96/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5363 - accuracy: 0.7987 - val_loss: 2.3464 - val_accuracy: 0.5360\n",
            "Epoch 97/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5316 - accuracy: 0.8003 - val_loss: 2.1678 - val_accuracy: 0.5454\n",
            "Epoch 98/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5308 - accuracy: 0.8022 - val_loss: 2.2794 - val_accuracy: 0.5338\n",
            "Epoch 99/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5204 - accuracy: 0.8043 - val_loss: 2.2378 - val_accuracy: 0.5304\n",
            "Epoch 100/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5136 - accuracy: 0.8102 - val_loss: 2.3453 - val_accuracy: 0.5338\n",
            "Epoch 101/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.5101 - accuracy: 0.8088 - val_loss: 2.3562 - val_accuracy: 0.5296\n",
            "Epoch 102/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4970 - accuracy: 0.8143 - val_loss: 2.3328 - val_accuracy: 0.5292\n",
            "Epoch 103/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5073 - accuracy: 0.8069 - val_loss: 2.3690 - val_accuracy: 0.5344\n",
            "Epoch 104/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4986 - accuracy: 0.8143 - val_loss: 2.3640 - val_accuracy: 0.5350\n",
            "Epoch 105/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5135 - accuracy: 0.8062 - val_loss: 2.4921 - val_accuracy: 0.5278\n",
            "Epoch 106/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5087 - accuracy: 0.8106 - val_loss: 2.3929 - val_accuracy: 0.5268\n",
            "Epoch 107/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4964 - accuracy: 0.8166 - val_loss: 2.4467 - val_accuracy: 0.5216\n",
            "Epoch 108/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4827 - accuracy: 0.8194 - val_loss: 2.5237 - val_accuracy: 0.5302\n",
            "Epoch 109/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4926 - accuracy: 0.8148 - val_loss: 2.3658 - val_accuracy: 0.5194\n",
            "Epoch 110/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4918 - accuracy: 0.8156 - val_loss: 2.4710 - val_accuracy: 0.5250\n",
            "Epoch 111/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5090 - accuracy: 0.8076 - val_loss: 2.5665 - val_accuracy: 0.5148\n",
            "Epoch 112/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4783 - accuracy: 0.8236 - val_loss: 2.4978 - val_accuracy: 0.5196\n",
            "Epoch 113/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.5023 - accuracy: 0.8114 - val_loss: 2.6037 - val_accuracy: 0.5148\n",
            "Epoch 114/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4930 - accuracy: 0.8155 - val_loss: 2.5072 - val_accuracy: 0.5228\n",
            "Epoch 115/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4772 - accuracy: 0.8219 - val_loss: 2.4545 - val_accuracy: 0.5190\n",
            "Epoch 116/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4878 - accuracy: 0.8181 - val_loss: 2.5755 - val_accuracy: 0.5304\n",
            "Epoch 117/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4863 - accuracy: 0.8162 - val_loss: 2.5822 - val_accuracy: 0.5272\n",
            "Epoch 118/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4750 - accuracy: 0.8243 - val_loss: 2.5659 - val_accuracy: 0.5228\n",
            "Epoch 119/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4819 - accuracy: 0.8204 - val_loss: 2.5842 - val_accuracy: 0.5126\n",
            "Epoch 120/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4677 - accuracy: 0.8256 - val_loss: 2.6145 - val_accuracy: 0.5214\n",
            "Epoch 121/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4767 - accuracy: 0.8206 - val_loss: 2.6437 - val_accuracy: 0.5152\n",
            "Epoch 122/200\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.4593 - accuracy: 0.8289 - val_loss: 2.6053 - val_accuracy: 0.5100\n",
            "Epoch 123/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4831 - accuracy: 0.8212 - val_loss: 2.6714 - val_accuracy: 0.5236\n",
            "Epoch 124/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4622 - accuracy: 0.8281 - val_loss: 2.6660 - val_accuracy: 0.5178\n",
            "Epoch 125/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4542 - accuracy: 0.8292 - val_loss: 2.6801 - val_accuracy: 0.5200\n",
            "Epoch 126/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4523 - accuracy: 0.8324 - val_loss: 2.7166 - val_accuracy: 0.5214\n",
            "Epoch 127/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4697 - accuracy: 0.8280 - val_loss: 2.6899 - val_accuracy: 0.5178\n",
            "Epoch 128/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4645 - accuracy: 0.8275 - val_loss: 2.6711 - val_accuracy: 0.5200\n",
            "Epoch 129/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4561 - accuracy: 0.8289 - val_loss: 2.7891 - val_accuracy: 0.5238\n",
            "Epoch 130/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4715 - accuracy: 0.8234 - val_loss: 2.6942 - val_accuracy: 0.5112\n",
            "Epoch 131/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4518 - accuracy: 0.8310 - val_loss: 2.6904 - val_accuracy: 0.5194\n",
            "Epoch 132/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4524 - accuracy: 0.8320 - val_loss: 2.8387 - val_accuracy: 0.5192\n",
            "Epoch 133/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4491 - accuracy: 0.8312 - val_loss: 2.8096 - val_accuracy: 0.5154\n",
            "Epoch 134/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4375 - accuracy: 0.8376 - val_loss: 2.7031 - val_accuracy: 0.5160\n",
            "Epoch 135/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4483 - accuracy: 0.8350 - val_loss: 2.9342 - val_accuracy: 0.5202\n",
            "Epoch 136/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4377 - accuracy: 0.8361 - val_loss: 2.7988 - val_accuracy: 0.5166\n",
            "Epoch 137/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4432 - accuracy: 0.8343 - val_loss: 2.8064 - val_accuracy: 0.5168\n",
            "Epoch 138/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4428 - accuracy: 0.8355 - val_loss: 3.0111 - val_accuracy: 0.5260\n",
            "Epoch 139/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4551 - accuracy: 0.8322 - val_loss: 2.9358 - val_accuracy: 0.5164\n",
            "Epoch 140/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4410 - accuracy: 0.8345 - val_loss: 2.8675 - val_accuracy: 0.5210\n",
            "Epoch 141/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4432 - accuracy: 0.8316 - val_loss: 2.9312 - val_accuracy: 0.5224\n",
            "Epoch 142/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4365 - accuracy: 0.8368 - val_loss: 2.8799 - val_accuracy: 0.5164\n",
            "Epoch 143/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4425 - accuracy: 0.8353 - val_loss: 2.9655 - val_accuracy: 0.5116\n",
            "Epoch 144/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4391 - accuracy: 0.8347 - val_loss: 3.0058 - val_accuracy: 0.5202\n",
            "Epoch 145/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4257 - accuracy: 0.8381 - val_loss: 2.8770 - val_accuracy: 0.5188\n",
            "Epoch 146/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4547 - accuracy: 0.8293 - val_loss: 2.9462 - val_accuracy: 0.5260\n",
            "Epoch 147/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4320 - accuracy: 0.8381 - val_loss: 2.9620 - val_accuracy: 0.5224\n",
            "Epoch 148/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4132 - accuracy: 0.8454 - val_loss: 3.0052 - val_accuracy: 0.5260\n",
            "Epoch 149/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4266 - accuracy: 0.8403 - val_loss: 2.9590 - val_accuracy: 0.5160\n",
            "Epoch 150/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4391 - accuracy: 0.8364 - val_loss: 2.9488 - val_accuracy: 0.5156\n",
            "Epoch 151/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4331 - accuracy: 0.8397 - val_loss: 3.0317 - val_accuracy: 0.5192\n",
            "Epoch 152/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4232 - accuracy: 0.8423 - val_loss: 3.0227 - val_accuracy: 0.5144\n",
            "Epoch 153/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4184 - accuracy: 0.8439 - val_loss: 3.0894 - val_accuracy: 0.5116\n",
            "Epoch 154/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4230 - accuracy: 0.8450 - val_loss: 3.0123 - val_accuracy: 0.5180\n",
            "Epoch 155/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4104 - accuracy: 0.8431 - val_loss: 3.0646 - val_accuracy: 0.5132\n",
            "Epoch 156/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4311 - accuracy: 0.8420 - val_loss: 3.0827 - val_accuracy: 0.5124\n",
            "Epoch 157/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4274 - accuracy: 0.8416 - val_loss: 3.0138 - val_accuracy: 0.5250\n",
            "Epoch 158/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4050 - accuracy: 0.8488 - val_loss: 3.1500 - val_accuracy: 0.5188\n",
            "Epoch 159/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4385 - accuracy: 0.8382 - val_loss: 3.0965 - val_accuracy: 0.5074\n",
            "Epoch 160/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4157 - accuracy: 0.8460 - val_loss: 3.1458 - val_accuracy: 0.5178\n",
            "Epoch 161/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4105 - accuracy: 0.8496 - val_loss: 3.1208 - val_accuracy: 0.5132\n",
            "Epoch 162/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4140 - accuracy: 0.8490 - val_loss: 3.1792 - val_accuracy: 0.5218\n",
            "Epoch 163/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4239 - accuracy: 0.8439 - val_loss: 3.0250 - val_accuracy: 0.5162\n",
            "Epoch 164/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3902 - accuracy: 0.8551 - val_loss: 3.2376 - val_accuracy: 0.5172\n",
            "Epoch 165/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4030 - accuracy: 0.8510 - val_loss: 3.1623 - val_accuracy: 0.5182\n",
            "Epoch 166/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4128 - accuracy: 0.8463 - val_loss: 3.2199 - val_accuracy: 0.5070\n",
            "Epoch 167/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4143 - accuracy: 0.8459 - val_loss: 3.1725 - val_accuracy: 0.5136\n",
            "Epoch 168/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4031 - accuracy: 0.8520 - val_loss: 3.0947 - val_accuracy: 0.5152\n",
            "Epoch 169/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3925 - accuracy: 0.8519 - val_loss: 3.2514 - val_accuracy: 0.5028\n",
            "Epoch 170/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4267 - accuracy: 0.8427 - val_loss: 3.1501 - val_accuracy: 0.5188\n",
            "Epoch 171/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3897 - accuracy: 0.8565 - val_loss: 3.2219 - val_accuracy: 0.5180\n",
            "Epoch 172/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4223 - accuracy: 0.8435 - val_loss: 3.2641 - val_accuracy: 0.5248\n",
            "Epoch 173/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3867 - accuracy: 0.8568 - val_loss: 3.2699 - val_accuracy: 0.5244\n",
            "Epoch 174/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3993 - accuracy: 0.8521 - val_loss: 3.3601 - val_accuracy: 0.5188\n",
            "Epoch 175/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3800 - accuracy: 0.8580 - val_loss: 3.2476 - val_accuracy: 0.5136\n",
            "Epoch 176/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4204 - accuracy: 0.8456 - val_loss: 3.2065 - val_accuracy: 0.5158\n",
            "Epoch 177/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3842 - accuracy: 0.8569 - val_loss: 3.4487 - val_accuracy: 0.5134\n",
            "Epoch 178/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4052 - accuracy: 0.8519 - val_loss: 3.4092 - val_accuracy: 0.5140\n",
            "Epoch 179/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.4052 - accuracy: 0.8496 - val_loss: 3.3629 - val_accuracy: 0.5064\n",
            "Epoch 180/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3886 - accuracy: 0.8546 - val_loss: 3.2369 - val_accuracy: 0.5074\n",
            "Epoch 181/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3801 - accuracy: 0.8588 - val_loss: 3.2325 - val_accuracy: 0.5160\n",
            "Epoch 182/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3814 - accuracy: 0.8578 - val_loss: 3.2799 - val_accuracy: 0.5046\n",
            "Epoch 183/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3748 - accuracy: 0.8591 - val_loss: 3.3784 - val_accuracy: 0.5188\n",
            "Epoch 184/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3910 - accuracy: 0.8546 - val_loss: 3.3480 - val_accuracy: 0.5160\n",
            "Epoch 185/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3887 - accuracy: 0.8539 - val_loss: 3.4055 - val_accuracy: 0.5152\n",
            "Epoch 186/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3872 - accuracy: 0.8562 - val_loss: 3.3318 - val_accuracy: 0.5128\n",
            "Epoch 187/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3883 - accuracy: 0.8555 - val_loss: 3.2778 - val_accuracy: 0.5128\n",
            "Epoch 188/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3854 - accuracy: 0.8594 - val_loss: 3.4146 - val_accuracy: 0.5144\n",
            "Epoch 189/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3963 - accuracy: 0.8539 - val_loss: 3.4617 - val_accuracy: 0.5076\n",
            "Epoch 190/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3811 - accuracy: 0.8586 - val_loss: 3.4701 - val_accuracy: 0.5060\n",
            "Epoch 191/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3875 - accuracy: 0.8550 - val_loss: 3.4090 - val_accuracy: 0.5066\n",
            "Epoch 192/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3728 - accuracy: 0.8606 - val_loss: 3.4516 - val_accuracy: 0.5132\n",
            "Epoch 193/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3766 - accuracy: 0.8618 - val_loss: 3.4633 - val_accuracy: 0.5018\n",
            "Epoch 194/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3823 - accuracy: 0.8564 - val_loss: 3.5098 - val_accuracy: 0.5138\n",
            "Epoch 195/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3771 - accuracy: 0.8625 - val_loss: 3.4647 - val_accuracy: 0.5092\n",
            "Epoch 196/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3767 - accuracy: 0.8588 - val_loss: 3.4458 - val_accuracy: 0.5176\n",
            "Epoch 197/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3575 - accuracy: 0.8660 - val_loss: 3.4823 - val_accuracy: 0.5078\n",
            "Epoch 198/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3854 - accuracy: 0.8557 - val_loss: 3.4778 - val_accuracy: 0.5144\n",
            "Epoch 199/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3716 - accuracy: 0.8615 - val_loss: 3.6693 - val_accuracy: 0.5126\n",
            "Epoch 200/200\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3804 - accuracy: 0.8604 - val_loss: 3.3961 - val_accuracy: 0.5142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0ca450c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_R8ZX0Ndp7Ah"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Nr2J_op7I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb28275-f1b3-445c-e7f3-ad469ec317df"
      },
      "source": [
        "inp = Input(shape=(depth, height, width))  # N.B. depth goes first in Keras\n",
        "\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "conv_1 = Convolution2D(conv_depth_1, kernel_size_1, kernel_size_1, padding='same', activation='relu')(inp)\n",
        "conv_2 = Convolution2D(conv_depth_1, kernel_size_1, kernel_size_1, padding='same', activation='relu')(conv_1)\n",
        "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
        "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
        "\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "conv_3 = Convolution2D(conv_depth_2, kernel_size_1, kernel_size_1, padding='same', activation='relu')(drop_1)\n",
        "conv_4 = Convolution2D(conv_depth_2, kernel_size_1, kernel_size_1, padding='same', activation='relu')(conv_3)\n",
        "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
        "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
        "\n",
        "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
        "flat = Flatten()(drop_2)\n",
        "hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)  # To define a model, just specify its input and output layers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # using the cross-entropy loss function\n",
        "              optimizer='adam',  # using the Adam optimiser\n",
        "              metrics=['accuracy'])  # reporting the accuracy\n",
        "\n",
        "model.fit(X_train, Y_train,  # Train the model using the training set...\n",
        "          batch_size=batch_size, epochs=num_epochs,\n",
        "          verbose=1, validation_split=0.1)  # ...holding out 10% of the data for validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1407/1407 [==============================] - 40s 7ms/step - loss: 1.9706 - accuracy: 0.2479 - val_loss: 1.4769 - val_accuracy: 0.4504\n",
            "Epoch 2/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5439 - accuracy: 0.4292 - val_loss: 1.3321 - val_accuracy: 0.5126\n",
            "Epoch 3/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4465 - accuracy: 0.4714 - val_loss: 1.2590 - val_accuracy: 0.5394\n",
            "Epoch 4/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3739 - accuracy: 0.4972 - val_loss: 1.2396 - val_accuracy: 0.5494\n",
            "Epoch 5/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3409 - accuracy: 0.5162 - val_loss: 1.1754 - val_accuracy: 0.5722\n",
            "Epoch 6/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3062 - accuracy: 0.5295 - val_loss: 1.1562 - val_accuracy: 0.5846\n",
            "Epoch 7/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2796 - accuracy: 0.5426 - val_loss: 1.1169 - val_accuracy: 0.6018\n",
            "Epoch 8/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2521 - accuracy: 0.5483 - val_loss: 1.1304 - val_accuracy: 0.5938\n",
            "Epoch 9/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2321 - accuracy: 0.5577 - val_loss: 1.1126 - val_accuracy: 0.5888\n",
            "Epoch 10/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2245 - accuracy: 0.5595 - val_loss: 1.0752 - val_accuracy: 0.6092\n",
            "Epoch 11/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1990 - accuracy: 0.5691 - val_loss: 1.0805 - val_accuracy: 0.6120\n",
            "Epoch 12/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1982 - accuracy: 0.5712 - val_loss: 1.0800 - val_accuracy: 0.6118\n",
            "Epoch 13/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1881 - accuracy: 0.5745 - val_loss: 1.0636 - val_accuracy: 0.6214\n",
            "Epoch 14/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1743 - accuracy: 0.5827 - val_loss: 1.0712 - val_accuracy: 0.6176\n",
            "Epoch 15/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1662 - accuracy: 0.5842 - val_loss: 1.0760 - val_accuracy: 0.6134\n",
            "Epoch 16/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1631 - accuracy: 0.5861 - val_loss: 1.0493 - val_accuracy: 0.6262\n",
            "Epoch 17/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1516 - accuracy: 0.5894 - val_loss: 1.0379 - val_accuracy: 0.6392\n",
            "Epoch 18/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1440 - accuracy: 0.5928 - val_loss: 1.0407 - val_accuracy: 0.6342\n",
            "Epoch 19/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1185 - accuracy: 0.5984 - val_loss: 1.0507 - val_accuracy: 0.6284\n",
            "Epoch 20/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1289 - accuracy: 0.5988 - val_loss: 1.0322 - val_accuracy: 0.6314\n",
            "Epoch 21/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1209 - accuracy: 0.6018 - val_loss: 1.0320 - val_accuracy: 0.6326\n",
            "Epoch 22/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1149 - accuracy: 0.6035 - val_loss: 1.0356 - val_accuracy: 0.6318\n",
            "Epoch 23/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1245 - accuracy: 0.5989 - val_loss: 1.0037 - val_accuracy: 0.6466\n",
            "Epoch 24/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1025 - accuracy: 0.6099 - val_loss: 1.0387 - val_accuracy: 0.6306\n",
            "Epoch 25/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1057 - accuracy: 0.6071 - val_loss: 1.0243 - val_accuracy: 0.6412\n",
            "Epoch 26/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1028 - accuracy: 0.6113 - val_loss: 1.0192 - val_accuracy: 0.6346\n",
            "Epoch 27/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1030 - accuracy: 0.6094 - val_loss: 1.0232 - val_accuracy: 0.6470\n",
            "Epoch 28/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0863 - accuracy: 0.6120 - val_loss: 1.0142 - val_accuracy: 0.6486\n",
            "Epoch 29/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0863 - accuracy: 0.6159 - val_loss: 1.0238 - val_accuracy: 0.6392\n",
            "Epoch 30/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0841 - accuracy: 0.6158 - val_loss: 1.0233 - val_accuracy: 0.6418\n",
            "Epoch 31/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0893 - accuracy: 0.6143 - val_loss: 1.0314 - val_accuracy: 0.6326\n",
            "Epoch 32/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0814 - accuracy: 0.6181 - val_loss: 1.0230 - val_accuracy: 0.6352\n",
            "Epoch 33/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0814 - accuracy: 0.6177 - val_loss: 1.0147 - val_accuracy: 0.6424\n",
            "Epoch 34/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0765 - accuracy: 0.6208 - val_loss: 1.0113 - val_accuracy: 0.6488\n",
            "Epoch 35/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0778 - accuracy: 0.6214 - val_loss: 1.0113 - val_accuracy: 0.6420\n",
            "Epoch 36/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0694 - accuracy: 0.6243 - val_loss: 1.0077 - val_accuracy: 0.6484\n",
            "Epoch 37/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0721 - accuracy: 0.6213 - val_loss: 1.0146 - val_accuracy: 0.6408\n",
            "Epoch 38/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0599 - accuracy: 0.6223 - val_loss: 1.0047 - val_accuracy: 0.6486\n",
            "Epoch 39/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0538 - accuracy: 0.6278 - val_loss: 1.0008 - val_accuracy: 0.6514\n",
            "Epoch 40/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0585 - accuracy: 0.6211 - val_loss: 0.9899 - val_accuracy: 0.6510\n",
            "Epoch 41/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0522 - accuracy: 0.6244 - val_loss: 0.9969 - val_accuracy: 0.6538\n",
            "Epoch 42/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0610 - accuracy: 0.6249 - val_loss: 0.9999 - val_accuracy: 0.6586\n",
            "Epoch 43/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0602 - accuracy: 0.6209 - val_loss: 0.9974 - val_accuracy: 0.6538\n",
            "Epoch 44/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0497 - accuracy: 0.6310 - val_loss: 1.0032 - val_accuracy: 0.6526\n",
            "Epoch 45/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0446 - accuracy: 0.6308 - val_loss: 0.9866 - val_accuracy: 0.6620\n",
            "Epoch 46/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0429 - accuracy: 0.6323 - val_loss: 0.9801 - val_accuracy: 0.6564\n",
            "Epoch 47/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0470 - accuracy: 0.6313 - val_loss: 0.9880 - val_accuracy: 0.6582\n",
            "Epoch 48/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0512 - accuracy: 0.6275 - val_loss: 1.0211 - val_accuracy: 0.6520\n",
            "Epoch 49/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0418 - accuracy: 0.6323 - val_loss: 0.9977 - val_accuracy: 0.6538\n",
            "Epoch 50/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0471 - accuracy: 0.6297 - val_loss: 1.0061 - val_accuracy: 0.6486\n",
            "Epoch 51/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0307 - accuracy: 0.6332 - val_loss: 1.0069 - val_accuracy: 0.6598\n",
            "Epoch 52/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0356 - accuracy: 0.6354 - val_loss: 1.0002 - val_accuracy: 0.6532\n",
            "Epoch 53/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0421 - accuracy: 0.6270 - val_loss: 1.0027 - val_accuracy: 0.6536\n",
            "Epoch 54/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0262 - accuracy: 0.6356 - val_loss: 0.9971 - val_accuracy: 0.6624\n",
            "Epoch 55/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0392 - accuracy: 0.6319 - val_loss: 0.9844 - val_accuracy: 0.6530\n",
            "Epoch 56/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0378 - accuracy: 0.6310 - val_loss: 0.9646 - val_accuracy: 0.6660\n",
            "Epoch 57/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0274 - accuracy: 0.6351 - val_loss: 0.9937 - val_accuracy: 0.6558\n",
            "Epoch 58/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0233 - accuracy: 0.6375 - val_loss: 0.9845 - val_accuracy: 0.6624\n",
            "Epoch 59/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0211 - accuracy: 0.6397 - val_loss: 0.9891 - val_accuracy: 0.6664\n",
            "Epoch 60/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0187 - accuracy: 0.6354 - val_loss: 0.9999 - val_accuracy: 0.6450\n",
            "Epoch 61/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0303 - accuracy: 0.6346 - val_loss: 0.9827 - val_accuracy: 0.6588\n",
            "Epoch 62/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0226 - accuracy: 0.6385 - val_loss: 0.9892 - val_accuracy: 0.6616\n",
            "Epoch 63/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0290 - accuracy: 0.6351 - val_loss: 0.9743 - val_accuracy: 0.6658\n",
            "Epoch 64/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0200 - accuracy: 0.6363 - val_loss: 0.9848 - val_accuracy: 0.6604\n",
            "Epoch 65/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0198 - accuracy: 0.6432 - val_loss: 0.9794 - val_accuracy: 0.6598\n",
            "Epoch 66/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0161 - accuracy: 0.6439 - val_loss: 0.9862 - val_accuracy: 0.6494\n",
            "Epoch 67/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0204 - accuracy: 0.6378 - val_loss: 0.9723 - val_accuracy: 0.6646\n",
            "Epoch 68/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0118 - accuracy: 0.6381 - val_loss: 0.9810 - val_accuracy: 0.6522\n",
            "Epoch 69/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0155 - accuracy: 0.6399 - val_loss: 0.9702 - val_accuracy: 0.6596\n",
            "Epoch 70/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0235 - accuracy: 0.6387 - val_loss: 0.9693 - val_accuracy: 0.6612\n",
            "Epoch 71/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0105 - accuracy: 0.6459 - val_loss: 0.9733 - val_accuracy: 0.6610\n",
            "Epoch 72/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0117 - accuracy: 0.6388 - val_loss: 0.9609 - val_accuracy: 0.6650\n",
            "Epoch 73/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0152 - accuracy: 0.6419 - val_loss: 0.9642 - val_accuracy: 0.6624\n",
            "Epoch 74/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0095 - accuracy: 0.6414 - val_loss: 0.9652 - val_accuracy: 0.6636\n",
            "Epoch 75/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9996 - accuracy: 0.6472 - val_loss: 0.9722 - val_accuracy: 0.6564\n",
            "Epoch 76/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0195 - accuracy: 0.6406 - val_loss: 0.9588 - val_accuracy: 0.6686\n",
            "Epoch 77/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0033 - accuracy: 0.6439 - val_loss: 0.9643 - val_accuracy: 0.6658\n",
            "Epoch 78/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9996 - accuracy: 0.6464 - val_loss: 0.9766 - val_accuracy: 0.6644\n",
            "Epoch 79/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0086 - accuracy: 0.6417 - val_loss: 0.9719 - val_accuracy: 0.6610\n",
            "Epoch 80/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0079 - accuracy: 0.6446 - val_loss: 0.9852 - val_accuracy: 0.6604\n",
            "Epoch 81/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9911 - accuracy: 0.6491 - val_loss: 0.9678 - val_accuracy: 0.6686\n",
            "Epoch 82/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9980 - accuracy: 0.6458 - val_loss: 0.9666 - val_accuracy: 0.6706\n",
            "Epoch 83/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9844 - accuracy: 0.6470 - val_loss: 0.9922 - val_accuracy: 0.6572\n",
            "Epoch 84/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0099 - accuracy: 0.6466 - val_loss: 0.9755 - val_accuracy: 0.6620\n",
            "Epoch 85/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0065 - accuracy: 0.6417 - val_loss: 0.9691 - val_accuracy: 0.6720\n",
            "Epoch 86/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9857 - accuracy: 0.6517 - val_loss: 0.9552 - val_accuracy: 0.6638\n",
            "Epoch 87/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9983 - accuracy: 0.6469 - val_loss: 0.9788 - val_accuracy: 0.6592\n",
            "Epoch 88/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9965 - accuracy: 0.6464 - val_loss: 0.9779 - val_accuracy: 0.6586\n",
            "Epoch 89/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9866 - accuracy: 0.6537 - val_loss: 0.9504 - val_accuracy: 0.6698\n",
            "Epoch 90/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9900 - accuracy: 0.6474 - val_loss: 0.9848 - val_accuracy: 0.6554\n",
            "Epoch 91/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9968 - accuracy: 0.6467 - val_loss: 0.9632 - val_accuracy: 0.6690\n",
            "Epoch 92/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9789 - accuracy: 0.6507 - val_loss: 0.9590 - val_accuracy: 0.6624\n",
            "Epoch 93/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9912 - accuracy: 0.6518 - val_loss: 0.9638 - val_accuracy: 0.6638\n",
            "Epoch 94/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9894 - accuracy: 0.6473 - val_loss: 0.9736 - val_accuracy: 0.6642\n",
            "Epoch 95/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9879 - accuracy: 0.6463 - val_loss: 0.9610 - val_accuracy: 0.6690\n",
            "Epoch 96/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9944 - accuracy: 0.6508 - val_loss: 0.9572 - val_accuracy: 0.6668\n",
            "Epoch 97/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9905 - accuracy: 0.6431 - val_loss: 0.9888 - val_accuracy: 0.6580\n",
            "Epoch 98/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9863 - accuracy: 0.6505 - val_loss: 0.9689 - val_accuracy: 0.6518\n",
            "Epoch 99/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9859 - accuracy: 0.6491 - val_loss: 0.9626 - val_accuracy: 0.6628\n",
            "Epoch 100/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9738 - accuracy: 0.6540 - val_loss: 0.9612 - val_accuracy: 0.6688\n",
            "Epoch 101/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9794 - accuracy: 0.6516 - val_loss: 0.9665 - val_accuracy: 0.6618\n",
            "Epoch 102/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9835 - accuracy: 0.6552 - val_loss: 0.9434 - val_accuracy: 0.6672\n",
            "Epoch 103/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9972 - accuracy: 0.6476 - val_loss: 0.9538 - val_accuracy: 0.6634\n",
            "Epoch 104/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9800 - accuracy: 0.6526 - val_loss: 0.9661 - val_accuracy: 0.6674\n",
            "Epoch 105/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9781 - accuracy: 0.6564 - val_loss: 0.9645 - val_accuracy: 0.6750\n",
            "Epoch 106/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9760 - accuracy: 0.6565 - val_loss: 0.9658 - val_accuracy: 0.6646\n",
            "Epoch 107/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9777 - accuracy: 0.6510 - val_loss: 0.9592 - val_accuracy: 0.6702\n",
            "Epoch 108/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9729 - accuracy: 0.6548 - val_loss: 0.9546 - val_accuracy: 0.6684\n",
            "Epoch 109/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9711 - accuracy: 0.6553 - val_loss: 0.9669 - val_accuracy: 0.6658\n",
            "Epoch 110/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9853 - accuracy: 0.6535 - val_loss: 0.9518 - val_accuracy: 0.6668\n",
            "Epoch 111/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9845 - accuracy: 0.6528 - val_loss: 0.9637 - val_accuracy: 0.6770\n",
            "Epoch 112/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9823 - accuracy: 0.6526 - val_loss: 0.9318 - val_accuracy: 0.6770\n",
            "Epoch 113/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9733 - accuracy: 0.6567 - val_loss: 0.9448 - val_accuracy: 0.6766\n",
            "Epoch 114/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9833 - accuracy: 0.6544 - val_loss: 0.9664 - val_accuracy: 0.6658\n",
            "Epoch 115/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9747 - accuracy: 0.6532 - val_loss: 0.9471 - val_accuracy: 0.6626\n",
            "Epoch 116/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9723 - accuracy: 0.6623 - val_loss: 0.9567 - val_accuracy: 0.6642\n",
            "Epoch 117/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9834 - accuracy: 0.6535 - val_loss: 0.9665 - val_accuracy: 0.6734\n",
            "Epoch 118/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9733 - accuracy: 0.6584 - val_loss: 0.9552 - val_accuracy: 0.6702\n",
            "Epoch 119/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9738 - accuracy: 0.6538 - val_loss: 0.9563 - val_accuracy: 0.6616\n",
            "Epoch 120/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9779 - accuracy: 0.6538 - val_loss: 0.9715 - val_accuracy: 0.6622\n",
            "Epoch 121/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9822 - accuracy: 0.6510 - val_loss: 0.9592 - val_accuracy: 0.6694\n",
            "Epoch 122/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9722 - accuracy: 0.6575 - val_loss: 0.9530 - val_accuracy: 0.6642\n",
            "Epoch 123/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9707 - accuracy: 0.6577 - val_loss: 0.9506 - val_accuracy: 0.6724\n",
            "Epoch 124/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9718 - accuracy: 0.6562 - val_loss: 0.9541 - val_accuracy: 0.6732\n",
            "Epoch 125/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9779 - accuracy: 0.6577 - val_loss: 0.9669 - val_accuracy: 0.6668\n",
            "Epoch 126/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9688 - accuracy: 0.6576 - val_loss: 0.9655 - val_accuracy: 0.6620\n",
            "Epoch 127/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9753 - accuracy: 0.6557 - val_loss: 0.9435 - val_accuracy: 0.6778\n",
            "Epoch 128/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9712 - accuracy: 0.6582 - val_loss: 0.9302 - val_accuracy: 0.6770\n",
            "Epoch 129/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9649 - accuracy: 0.6576 - val_loss: 0.9517 - val_accuracy: 0.6638\n",
            "Epoch 130/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9633 - accuracy: 0.6616 - val_loss: 0.9371 - val_accuracy: 0.6708\n",
            "Epoch 131/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9502 - accuracy: 0.6639 - val_loss: 0.9375 - val_accuracy: 0.6736\n",
            "Epoch 132/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9550 - accuracy: 0.6660 - val_loss: 0.9518 - val_accuracy: 0.6690\n",
            "Epoch 133/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9630 - accuracy: 0.6617 - val_loss: 0.9480 - val_accuracy: 0.6674\n",
            "Epoch 134/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9681 - accuracy: 0.6611 - val_loss: 0.9242 - val_accuracy: 0.6740\n",
            "Epoch 135/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9698 - accuracy: 0.6584 - val_loss: 0.9519 - val_accuracy: 0.6692\n",
            "Epoch 136/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9624 - accuracy: 0.6629 - val_loss: 0.9430 - val_accuracy: 0.6716\n",
            "Epoch 137/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9646 - accuracy: 0.6596 - val_loss: 0.9432 - val_accuracy: 0.6668\n",
            "Epoch 138/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9625 - accuracy: 0.6630 - val_loss: 0.9398 - val_accuracy: 0.6658\n",
            "Epoch 139/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9613 - accuracy: 0.6574 - val_loss: 0.9375 - val_accuracy: 0.6740\n",
            "Epoch 140/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9669 - accuracy: 0.6574 - val_loss: 0.9498 - val_accuracy: 0.6650\n",
            "Epoch 141/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9667 - accuracy: 0.6625 - val_loss: 0.9607 - val_accuracy: 0.6676\n",
            "Epoch 142/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9584 - accuracy: 0.6626 - val_loss: 0.9412 - val_accuracy: 0.6754\n",
            "Epoch 143/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9578 - accuracy: 0.6613 - val_loss: 0.9452 - val_accuracy: 0.6772\n",
            "Epoch 144/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9488 - accuracy: 0.6658 - val_loss: 0.9284 - val_accuracy: 0.6764\n",
            "Epoch 145/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9554 - accuracy: 0.6613 - val_loss: 0.9432 - val_accuracy: 0.6630\n",
            "Epoch 146/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9667 - accuracy: 0.6625 - val_loss: 0.9576 - val_accuracy: 0.6638\n",
            "Epoch 147/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9560 - accuracy: 0.6638 - val_loss: 0.9377 - val_accuracy: 0.6718\n",
            "Epoch 148/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9488 - accuracy: 0.6642 - val_loss: 0.9467 - val_accuracy: 0.6724\n",
            "Epoch 149/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9628 - accuracy: 0.6630 - val_loss: 0.9381 - val_accuracy: 0.6712\n",
            "Epoch 150/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9575 - accuracy: 0.6653 - val_loss: 0.9556 - val_accuracy: 0.6642\n",
            "Epoch 151/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9481 - accuracy: 0.6692 - val_loss: 0.9251 - val_accuracy: 0.6798\n",
            "Epoch 152/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9544 - accuracy: 0.6632 - val_loss: 0.9379 - val_accuracy: 0.6758\n",
            "Epoch 153/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9647 - accuracy: 0.6578 - val_loss: 0.9371 - val_accuracy: 0.6718\n",
            "Epoch 154/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9550 - accuracy: 0.6644 - val_loss: 0.9516 - val_accuracy: 0.6700\n",
            "Epoch 155/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9536 - accuracy: 0.6631 - val_loss: 0.9504 - val_accuracy: 0.6712\n",
            "Epoch 156/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9562 - accuracy: 0.6590 - val_loss: 0.9246 - val_accuracy: 0.6786\n",
            "Epoch 157/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9514 - accuracy: 0.6630 - val_loss: 0.9369 - val_accuracy: 0.6700\n",
            "Epoch 158/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9555 - accuracy: 0.6622 - val_loss: 0.9672 - val_accuracy: 0.6642\n",
            "Epoch 159/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9533 - accuracy: 0.6643 - val_loss: 0.9370 - val_accuracy: 0.6754\n",
            "Epoch 160/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9491 - accuracy: 0.6653 - val_loss: 0.9386 - val_accuracy: 0.6734\n",
            "Epoch 161/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9583 - accuracy: 0.6600 - val_loss: 0.9454 - val_accuracy: 0.6736\n",
            "Epoch 162/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9351 - accuracy: 0.6732 - val_loss: 0.9405 - val_accuracy: 0.6746\n",
            "Epoch 163/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9551 - accuracy: 0.6668 - val_loss: 0.9404 - val_accuracy: 0.6738\n",
            "Epoch 164/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9595 - accuracy: 0.6640 - val_loss: 0.9285 - val_accuracy: 0.6724\n",
            "Epoch 165/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9550 - accuracy: 0.6630 - val_loss: 0.9425 - val_accuracy: 0.6682\n",
            "Epoch 166/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9556 - accuracy: 0.6648 - val_loss: 0.9511 - val_accuracy: 0.6622\n",
            "Epoch 167/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9526 - accuracy: 0.6676 - val_loss: 0.9475 - val_accuracy: 0.6772\n",
            "Epoch 168/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9527 - accuracy: 0.6690 - val_loss: 0.9427 - val_accuracy: 0.6764\n",
            "Epoch 169/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9386 - accuracy: 0.6673 - val_loss: 0.9328 - val_accuracy: 0.6782\n",
            "Epoch 170/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9429 - accuracy: 0.6701 - val_loss: 0.9412 - val_accuracy: 0.6726\n",
            "Epoch 171/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9409 - accuracy: 0.6670 - val_loss: 0.9347 - val_accuracy: 0.6734\n",
            "Epoch 172/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9424 - accuracy: 0.6669 - val_loss: 0.9405 - val_accuracy: 0.6750\n",
            "Epoch 173/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9398 - accuracy: 0.6683 - val_loss: 0.9257 - val_accuracy: 0.6762\n",
            "Epoch 174/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9472 - accuracy: 0.6679 - val_loss: 0.9267 - val_accuracy: 0.6756\n",
            "Epoch 175/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9563 - accuracy: 0.6647 - val_loss: 0.9492 - val_accuracy: 0.6708\n",
            "Epoch 176/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9458 - accuracy: 0.6697 - val_loss: 0.9452 - val_accuracy: 0.6736\n",
            "Epoch 177/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9342 - accuracy: 0.6709 - val_loss: 0.9440 - val_accuracy: 0.6720\n",
            "Epoch 178/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9401 - accuracy: 0.6670 - val_loss: 0.9200 - val_accuracy: 0.6770\n",
            "Epoch 179/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9437 - accuracy: 0.6664 - val_loss: 0.9366 - val_accuracy: 0.6754\n",
            "Epoch 180/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9520 - accuracy: 0.6682 - val_loss: 0.9183 - val_accuracy: 0.6814\n",
            "Epoch 181/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9405 - accuracy: 0.6673 - val_loss: 0.9316 - val_accuracy: 0.6728\n",
            "Epoch 182/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9546 - accuracy: 0.6624 - val_loss: 0.9421 - val_accuracy: 0.6678\n",
            "Epoch 183/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9386 - accuracy: 0.6652 - val_loss: 0.9330 - val_accuracy: 0.6748\n",
            "Epoch 184/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9433 - accuracy: 0.6703 - val_loss: 0.9346 - val_accuracy: 0.6746\n",
            "Epoch 185/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9500 - accuracy: 0.6674 - val_loss: 0.9147 - val_accuracy: 0.6790\n",
            "Epoch 186/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9540 - accuracy: 0.6644 - val_loss: 0.9245 - val_accuracy: 0.6732\n",
            "Epoch 187/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9507 - accuracy: 0.6664 - val_loss: 0.9348 - val_accuracy: 0.6708\n",
            "Epoch 188/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9481 - accuracy: 0.6636 - val_loss: 0.9361 - val_accuracy: 0.6780\n",
            "Epoch 189/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9585 - accuracy: 0.6646 - val_loss: 0.9208 - val_accuracy: 0.6802\n",
            "Epoch 190/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9555 - accuracy: 0.6661 - val_loss: 0.9444 - val_accuracy: 0.6748\n",
            "Epoch 191/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9412 - accuracy: 0.6748 - val_loss: 0.9448 - val_accuracy: 0.6748\n",
            "Epoch 192/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9471 - accuracy: 0.6664 - val_loss: 0.9341 - val_accuracy: 0.6726\n",
            "Epoch 193/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9444 - accuracy: 0.6665 - val_loss: 0.9251 - val_accuracy: 0.6698\n",
            "Epoch 194/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9428 - accuracy: 0.6710 - val_loss: 0.9228 - val_accuracy: 0.6768\n",
            "Epoch 195/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9412 - accuracy: 0.6711 - val_loss: 0.9252 - val_accuracy: 0.6818\n",
            "Epoch 196/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9448 - accuracy: 0.6681 - val_loss: 0.9295 - val_accuracy: 0.6796\n",
            "Epoch 197/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9558 - accuracy: 0.6619 - val_loss: 0.9138 - val_accuracy: 0.6826\n",
            "Epoch 198/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9345 - accuracy: 0.6700 - val_loss: 0.9225 - val_accuracy: 0.6844\n",
            "Epoch 199/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9489 - accuracy: 0.6659 - val_loss: 0.9296 - val_accuracy: 0.6730\n",
            "Epoch 200/200\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9470 - accuracy: 0.6689 - val_loss: 0.9464 - val_accuracy: 0.6632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7facd308dbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdxN6CA5qMTy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bxCNCzbqMaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb86836c-bfe1-4cf2-921a-72337aca27f4"
      },
      "source": [
        "inp = Input(shape=(depth, height, width))  # N.B. depth goes first in Keras\n",
        "\n",
        "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
        "conv_1 = Convolution2D(conv_depth_1, kernel_size_2, kernel_size_2, padding='same', activation='relu')(inp)\n",
        "conv_2 = Convolution2D(conv_depth_1, kernel_size_2, kernel_size_2, padding='same', activation='relu')(conv_1)\n",
        "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_2)\n",
        "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
        "\n",
        "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
        "conv_3 = Convolution2D(conv_depth_2, kernel_size_2, kernel_size_2, padding='same', activation='relu')(drop_1)\n",
        "conv_4 = Convolution2D(conv_depth_2, kernel_size_2, kernel_size_2, padding='same', activation='relu')(conv_3)\n",
        "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same')(conv_4)\n",
        "drop_2 = Dropout(drop_prob_1)(pool_2)\n",
        "\n",
        "# Now flatten to 1D, apply Dense -> ReLU (with dropout) -> softmax\n",
        "flat = Flatten()(drop_2)\n",
        "hidden = Dense(hidden_size, activation='relu')(flat)\n",
        "drop_3 = Dropout(drop_prob_2)(hidden)\n",
        "out = Dense(num_classes, activation='softmax')(drop_3)\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)  # To define a model, just specify its input and output layers\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # using the cross-entropy loss function\n",
        "              optimizer='adam',  # using the Adam optimiser\n",
        "              metrics=['accuracy'])  # reporting the accuracy\n",
        "\n",
        "model.fit(X_train, Y_train,  # Train the model using the training set...\n",
        "          batch_size=batch_size, epochs=num_epochs,\n",
        "          verbose=1, validation_split=0.1)  # ...holding out 10% of the data for validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1407/1407 [==============================] - 10s 6ms/step - loss: 2.1491 - accuracy: 0.1685 - val_loss: 1.8957 - val_accuracy: 0.2606\n",
            "Epoch 2/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9235 - accuracy: 0.2538 - val_loss: 1.8075 - val_accuracy: 0.3074\n",
            "Epoch 3/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8454 - accuracy: 0.2872 - val_loss: 1.7012 - val_accuracy: 0.3548\n",
            "Epoch 4/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7775 - accuracy: 0.3195 - val_loss: 1.6554 - val_accuracy: 0.3734\n",
            "Epoch 5/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7380 - accuracy: 0.3385 - val_loss: 1.6153 - val_accuracy: 0.3952\n",
            "Epoch 6/200\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7112 - accuracy: 0.3499 - val_loss: 1.6021 - val_accuracy: 0.4008\n",
            "Epoch 7/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6816 - accuracy: 0.3693 - val_loss: 1.5721 - val_accuracy: 0.4154\n",
            "Epoch 8/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6672 - accuracy: 0.3726 - val_loss: 1.6060 - val_accuracy: 0.3896\n",
            "Epoch 9/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6499 - accuracy: 0.3884 - val_loss: 1.5398 - val_accuracy: 0.4186\n",
            "Epoch 10/200\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6276 - accuracy: 0.3878 - val_loss: 1.5331 - val_accuracy: 0.4442\n",
            "Epoch 11/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6122 - accuracy: 0.4014 - val_loss: 1.5396 - val_accuracy: 0.4450\n",
            "Epoch 12/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6021 - accuracy: 0.4056 - val_loss: 1.5106 - val_accuracy: 0.4368\n",
            "Epoch 13/200\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5958 - accuracy: 0.4108 - val_loss: 1.5142 - val_accuracy: 0.4486\n",
            "Epoch 14/200\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5829 - accuracy: 0.4163 - val_loss: 1.5059 - val_accuracy: 0.4482\n",
            "Epoch 15/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5734 - accuracy: 0.4230 - val_loss: 1.4997 - val_accuracy: 0.4590\n",
            "Epoch 16/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5628 - accuracy: 0.4260 - val_loss: 1.4782 - val_accuracy: 0.4580\n",
            "Epoch 17/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5494 - accuracy: 0.4333 - val_loss: 1.5058 - val_accuracy: 0.4458\n",
            "Epoch 18/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5430 - accuracy: 0.4399 - val_loss: 1.4826 - val_accuracy: 0.4630\n",
            "Epoch 19/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5280 - accuracy: 0.4441 - val_loss: 1.4713 - val_accuracy: 0.4680\n",
            "Epoch 20/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5291 - accuracy: 0.4413 - val_loss: 1.4670 - val_accuracy: 0.4546\n",
            "Epoch 21/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5264 - accuracy: 0.4413 - val_loss: 1.4698 - val_accuracy: 0.4710\n",
            "Epoch 22/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5179 - accuracy: 0.4460 - val_loss: 1.4655 - val_accuracy: 0.4758\n",
            "Epoch 23/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5081 - accuracy: 0.4494 - val_loss: 1.5522 - val_accuracy: 0.4488\n",
            "Epoch 24/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5114 - accuracy: 0.4468 - val_loss: 1.4606 - val_accuracy: 0.4624\n",
            "Epoch 25/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4986 - accuracy: 0.4564 - val_loss: 1.4663 - val_accuracy: 0.4710\n",
            "Epoch 26/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5000 - accuracy: 0.4549 - val_loss: 1.4448 - val_accuracy: 0.4774\n",
            "Epoch 27/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4823 - accuracy: 0.4641 - val_loss: 1.4843 - val_accuracy: 0.4510\n",
            "Epoch 28/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4931 - accuracy: 0.4585 - val_loss: 1.4611 - val_accuracy: 0.4680\n",
            "Epoch 29/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4735 - accuracy: 0.4661 - val_loss: 1.4556 - val_accuracy: 0.4758\n",
            "Epoch 30/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4709 - accuracy: 0.4631 - val_loss: 1.4655 - val_accuracy: 0.4718\n",
            "Epoch 31/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4690 - accuracy: 0.4622 - val_loss: 1.4696 - val_accuracy: 0.4838\n",
            "Epoch 32/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4719 - accuracy: 0.4676 - val_loss: 1.4423 - val_accuracy: 0.4810\n",
            "Epoch 33/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4652 - accuracy: 0.4727 - val_loss: 1.4437 - val_accuracy: 0.4860\n",
            "Epoch 34/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4515 - accuracy: 0.4745 - val_loss: 1.4279 - val_accuracy: 0.4828\n",
            "Epoch 35/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4619 - accuracy: 0.4684 - val_loss: 1.4468 - val_accuracy: 0.4864\n",
            "Epoch 36/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4590 - accuracy: 0.4679 - val_loss: 1.4478 - val_accuracy: 0.4858\n",
            "Epoch 37/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4634 - accuracy: 0.4706 - val_loss: 1.4657 - val_accuracy: 0.4772\n",
            "Epoch 38/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4493 - accuracy: 0.4738 - val_loss: 1.4431 - val_accuracy: 0.4918\n",
            "Epoch 39/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4454 - accuracy: 0.4790 - val_loss: 1.4588 - val_accuracy: 0.4910\n",
            "Epoch 40/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4486 - accuracy: 0.4757 - val_loss: 1.4448 - val_accuracy: 0.4874\n",
            "Epoch 41/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4366 - accuracy: 0.4814 - val_loss: 1.4410 - val_accuracy: 0.4912\n",
            "Epoch 42/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4433 - accuracy: 0.4767 - val_loss: 1.4471 - val_accuracy: 0.4818\n",
            "Epoch 43/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4319 - accuracy: 0.4807 - val_loss: 1.4622 - val_accuracy: 0.4822\n",
            "Epoch 44/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4425 - accuracy: 0.4776 - val_loss: 1.4345 - val_accuracy: 0.4902\n",
            "Epoch 45/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4377 - accuracy: 0.4804 - val_loss: 1.4448 - val_accuracy: 0.4864\n",
            "Epoch 46/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4374 - accuracy: 0.4836 - val_loss: 1.4441 - val_accuracy: 0.4820\n",
            "Epoch 47/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4402 - accuracy: 0.4794 - val_loss: 1.4383 - val_accuracy: 0.4914\n",
            "Epoch 48/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4403 - accuracy: 0.4818 - val_loss: 1.4656 - val_accuracy: 0.4854\n",
            "Epoch 49/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4371 - accuracy: 0.4807 - val_loss: 1.4361 - val_accuracy: 0.4878\n",
            "Epoch 50/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4208 - accuracy: 0.4903 - val_loss: 1.4492 - val_accuracy: 0.4970\n",
            "Epoch 51/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4351 - accuracy: 0.4814 - val_loss: 1.4359 - val_accuracy: 0.4990\n",
            "Epoch 52/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4305 - accuracy: 0.4809 - val_loss: 1.4100 - val_accuracy: 0.5030\n",
            "Epoch 53/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4132 - accuracy: 0.4952 - val_loss: 1.4282 - val_accuracy: 0.4948\n",
            "Epoch 54/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4275 - accuracy: 0.4831 - val_loss: 1.4322 - val_accuracy: 0.4820\n",
            "Epoch 55/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4210 - accuracy: 0.4878 - val_loss: 1.4166 - val_accuracy: 0.4918\n",
            "Epoch 56/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4286 - accuracy: 0.4861 - val_loss: 1.4226 - val_accuracy: 0.5036\n",
            "Epoch 57/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4088 - accuracy: 0.4913 - val_loss: 1.4211 - val_accuracy: 0.4950\n",
            "Epoch 58/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4213 - accuracy: 0.4898 - val_loss: 1.4429 - val_accuracy: 0.4976\n",
            "Epoch 59/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4145 - accuracy: 0.4919 - val_loss: 1.4206 - val_accuracy: 0.4930\n",
            "Epoch 60/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4145 - accuracy: 0.4923 - val_loss: 1.4566 - val_accuracy: 0.4890\n",
            "Epoch 61/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4071 - accuracy: 0.4933 - val_loss: 1.4163 - val_accuracy: 0.5040\n",
            "Epoch 62/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4044 - accuracy: 0.4941 - val_loss: 1.4329 - val_accuracy: 0.4898\n",
            "Epoch 63/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3964 - accuracy: 0.4951 - val_loss: 1.4277 - val_accuracy: 0.4944\n",
            "Epoch 64/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4009 - accuracy: 0.4919 - val_loss: 1.4415 - val_accuracy: 0.4956\n",
            "Epoch 65/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4016 - accuracy: 0.4973 - val_loss: 1.4274 - val_accuracy: 0.5012\n",
            "Epoch 66/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4059 - accuracy: 0.4889 - val_loss: 1.4509 - val_accuracy: 0.4886\n",
            "Epoch 67/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4142 - accuracy: 0.4871 - val_loss: 1.4299 - val_accuracy: 0.4888\n",
            "Epoch 68/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4114 - accuracy: 0.4931 - val_loss: 1.4291 - val_accuracy: 0.4926\n",
            "Epoch 69/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4058 - accuracy: 0.4983 - val_loss: 1.4232 - val_accuracy: 0.5002\n",
            "Epoch 70/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4131 - accuracy: 0.4936 - val_loss: 1.4241 - val_accuracy: 0.4890\n",
            "Epoch 71/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4059 - accuracy: 0.4936 - val_loss: 1.4158 - val_accuracy: 0.4914\n",
            "Epoch 72/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4008 - accuracy: 0.4946 - val_loss: 1.4349 - val_accuracy: 0.4890\n",
            "Epoch 73/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3980 - accuracy: 0.4955 - val_loss: 1.4119 - val_accuracy: 0.4952\n",
            "Epoch 74/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3926 - accuracy: 0.5001 - val_loss: 1.4290 - val_accuracy: 0.4960\n",
            "Epoch 75/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3961 - accuracy: 0.4939 - val_loss: 1.4174 - val_accuracy: 0.5004\n",
            "Epoch 76/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4003 - accuracy: 0.4987 - val_loss: 1.4330 - val_accuracy: 0.4912\n",
            "Epoch 77/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3981 - accuracy: 0.4964 - val_loss: 1.4169 - val_accuracy: 0.4964\n",
            "Epoch 78/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3984 - accuracy: 0.5010 - val_loss: 1.4297 - val_accuracy: 0.4942\n",
            "Epoch 79/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4027 - accuracy: 0.4961 - val_loss: 1.4278 - val_accuracy: 0.4918\n",
            "Epoch 80/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3959 - accuracy: 0.4998 - val_loss: 1.4193 - val_accuracy: 0.4940\n",
            "Epoch 81/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3912 - accuracy: 0.5016 - val_loss: 1.4317 - val_accuracy: 0.5030\n",
            "Epoch 82/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3949 - accuracy: 0.4977 - val_loss: 1.4238 - val_accuracy: 0.4986\n",
            "Epoch 83/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3876 - accuracy: 0.5013 - val_loss: 1.4082 - val_accuracy: 0.4958\n",
            "Epoch 84/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3932 - accuracy: 0.4995 - val_loss: 1.4130 - val_accuracy: 0.4998\n",
            "Epoch 85/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3812 - accuracy: 0.5014 - val_loss: 1.4124 - val_accuracy: 0.4906\n",
            "Epoch 86/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3868 - accuracy: 0.4998 - val_loss: 1.4238 - val_accuracy: 0.4934\n",
            "Epoch 87/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3832 - accuracy: 0.5005 - val_loss: 1.4278 - val_accuracy: 0.4908\n",
            "Epoch 88/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3827 - accuracy: 0.5066 - val_loss: 1.4159 - val_accuracy: 0.5010\n",
            "Epoch 89/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3920 - accuracy: 0.4999 - val_loss: 1.4399 - val_accuracy: 0.5022\n",
            "Epoch 90/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3853 - accuracy: 0.5054 - val_loss: 1.4293 - val_accuracy: 0.4774\n",
            "Epoch 91/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3929 - accuracy: 0.4940 - val_loss: 1.4647 - val_accuracy: 0.4832\n",
            "Epoch 92/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3780 - accuracy: 0.5033 - val_loss: 1.4248 - val_accuracy: 0.4978\n",
            "Epoch 93/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3873 - accuracy: 0.5014 - val_loss: 1.4260 - val_accuracy: 0.4890\n",
            "Epoch 94/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3766 - accuracy: 0.5046 - val_loss: 1.4304 - val_accuracy: 0.4954\n",
            "Epoch 95/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3859 - accuracy: 0.5010 - val_loss: 1.4185 - val_accuracy: 0.4916\n",
            "Epoch 96/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3900 - accuracy: 0.5019 - val_loss: 1.4328 - val_accuracy: 0.4950\n",
            "Epoch 97/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3917 - accuracy: 0.4995 - val_loss: 1.4276 - val_accuracy: 0.4874\n",
            "Epoch 98/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3753 - accuracy: 0.5082 - val_loss: 1.4171 - val_accuracy: 0.4966\n",
            "Epoch 99/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3784 - accuracy: 0.4991 - val_loss: 1.4065 - val_accuracy: 0.4998\n",
            "Epoch 100/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3796 - accuracy: 0.4994 - val_loss: 1.4088 - val_accuracy: 0.4934\n",
            "Epoch 101/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3767 - accuracy: 0.5093 - val_loss: 1.4612 - val_accuracy: 0.4792\n",
            "Epoch 102/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3795 - accuracy: 0.5044 - val_loss: 1.4445 - val_accuracy: 0.4938\n",
            "Epoch 103/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3730 - accuracy: 0.5083 - val_loss: 1.4250 - val_accuracy: 0.4962\n",
            "Epoch 104/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3755 - accuracy: 0.5056 - val_loss: 1.4041 - val_accuracy: 0.4988\n",
            "Epoch 105/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3886 - accuracy: 0.5067 - val_loss: 1.4236 - val_accuracy: 0.4964\n",
            "Epoch 106/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3723 - accuracy: 0.5083 - val_loss: 1.4138 - val_accuracy: 0.5024\n",
            "Epoch 107/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3696 - accuracy: 0.5114 - val_loss: 1.4186 - val_accuracy: 0.4966\n",
            "Epoch 108/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3772 - accuracy: 0.5028 - val_loss: 1.4079 - val_accuracy: 0.5076\n",
            "Epoch 109/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3725 - accuracy: 0.5051 - val_loss: 1.4259 - val_accuracy: 0.4964\n",
            "Epoch 110/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3722 - accuracy: 0.5058 - val_loss: 1.4402 - val_accuracy: 0.4786\n",
            "Epoch 111/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3786 - accuracy: 0.5066 - val_loss: 1.4191 - val_accuracy: 0.4954\n",
            "Epoch 112/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3650 - accuracy: 0.5111 - val_loss: 1.4348 - val_accuracy: 0.4884\n",
            "Epoch 113/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3736 - accuracy: 0.5064 - val_loss: 1.4170 - val_accuracy: 0.4996\n",
            "Epoch 114/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3667 - accuracy: 0.5110 - val_loss: 1.4176 - val_accuracy: 0.4864\n",
            "Epoch 115/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3675 - accuracy: 0.5069 - val_loss: 1.4141 - val_accuracy: 0.4932\n",
            "Epoch 116/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3731 - accuracy: 0.5007 - val_loss: 1.4360 - val_accuracy: 0.4888\n",
            "Epoch 117/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3723 - accuracy: 0.5081 - val_loss: 1.4035 - val_accuracy: 0.5048\n",
            "Epoch 118/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3764 - accuracy: 0.5041 - val_loss: 1.4069 - val_accuracy: 0.4990\n",
            "Epoch 119/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3721 - accuracy: 0.5122 - val_loss: 1.4247 - val_accuracy: 0.4880\n",
            "Epoch 120/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3713 - accuracy: 0.5088 - val_loss: 1.4139 - val_accuracy: 0.4910\n",
            "Epoch 121/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3590 - accuracy: 0.5115 - val_loss: 1.4332 - val_accuracy: 0.4858\n",
            "Epoch 122/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3589 - accuracy: 0.5095 - val_loss: 1.3985 - val_accuracy: 0.5010\n",
            "Epoch 123/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3701 - accuracy: 0.5067 - val_loss: 1.4215 - val_accuracy: 0.4952\n",
            "Epoch 124/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3669 - accuracy: 0.5037 - val_loss: 1.4204 - val_accuracy: 0.5020\n",
            "Epoch 125/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3612 - accuracy: 0.5072 - val_loss: 1.4358 - val_accuracy: 0.4898\n",
            "Epoch 126/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3751 - accuracy: 0.5095 - val_loss: 1.4411 - val_accuracy: 0.4790\n",
            "Epoch 127/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3643 - accuracy: 0.5093 - val_loss: 1.4093 - val_accuracy: 0.4988\n",
            "Epoch 128/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3635 - accuracy: 0.5102 - val_loss: 1.4070 - val_accuracy: 0.4944\n",
            "Epoch 129/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3655 - accuracy: 0.5104 - val_loss: 1.4542 - val_accuracy: 0.4888\n",
            "Epoch 130/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3694 - accuracy: 0.5078 - val_loss: 1.4188 - val_accuracy: 0.5004\n",
            "Epoch 131/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3648 - accuracy: 0.5104 - val_loss: 1.4176 - val_accuracy: 0.4920\n",
            "Epoch 132/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3637 - accuracy: 0.5123 - val_loss: 1.4174 - val_accuracy: 0.4878\n",
            "Epoch 133/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3633 - accuracy: 0.5109 - val_loss: 1.4179 - val_accuracy: 0.4956\n",
            "Epoch 134/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3644 - accuracy: 0.5093 - val_loss: 1.4536 - val_accuracy: 0.4768\n",
            "Epoch 135/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3749 - accuracy: 0.5050 - val_loss: 1.4230 - val_accuracy: 0.4924\n",
            "Epoch 136/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3600 - accuracy: 0.5112 - val_loss: 1.4289 - val_accuracy: 0.4916\n",
            "Epoch 137/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3619 - accuracy: 0.5145 - val_loss: 1.4161 - val_accuracy: 0.4992\n",
            "Epoch 138/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3539 - accuracy: 0.5120 - val_loss: 1.4206 - val_accuracy: 0.4922\n",
            "Epoch 139/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3530 - accuracy: 0.5151 - val_loss: 1.4025 - val_accuracy: 0.4946\n",
            "Epoch 140/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3530 - accuracy: 0.5161 - val_loss: 1.4143 - val_accuracy: 0.4982\n",
            "Epoch 141/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3566 - accuracy: 0.5131 - val_loss: 1.4300 - val_accuracy: 0.4888\n",
            "Epoch 142/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3637 - accuracy: 0.5090 - val_loss: 1.4113 - val_accuracy: 0.4958\n",
            "Epoch 143/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3517 - accuracy: 0.5182 - val_loss: 1.4401 - val_accuracy: 0.4786\n",
            "Epoch 144/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3677 - accuracy: 0.5052 - val_loss: 1.4080 - val_accuracy: 0.4962\n",
            "Epoch 145/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3552 - accuracy: 0.5137 - val_loss: 1.4143 - val_accuracy: 0.4876\n",
            "Epoch 146/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3584 - accuracy: 0.5169 - val_loss: 1.4180 - val_accuracy: 0.4896\n",
            "Epoch 147/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3620 - accuracy: 0.5116 - val_loss: 1.4292 - val_accuracy: 0.4890\n",
            "Epoch 148/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3464 - accuracy: 0.5121 - val_loss: 1.4048 - val_accuracy: 0.4982\n",
            "Epoch 149/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3518 - accuracy: 0.5161 - val_loss: 1.4233 - val_accuracy: 0.4912\n",
            "Epoch 150/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3524 - accuracy: 0.5197 - val_loss: 1.4342 - val_accuracy: 0.4924\n",
            "Epoch 151/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3626 - accuracy: 0.5133 - val_loss: 1.4334 - val_accuracy: 0.4862\n",
            "Epoch 152/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3432 - accuracy: 0.5193 - val_loss: 1.4150 - val_accuracy: 0.4912\n",
            "Epoch 153/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3602 - accuracy: 0.5140 - val_loss: 1.4129 - val_accuracy: 0.4920\n",
            "Epoch 154/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3544 - accuracy: 0.5164 - val_loss: 1.4387 - val_accuracy: 0.4802\n",
            "Epoch 155/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3604 - accuracy: 0.5141 - val_loss: 1.4001 - val_accuracy: 0.5016\n",
            "Epoch 156/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3543 - accuracy: 0.5152 - val_loss: 1.4064 - val_accuracy: 0.4936\n",
            "Epoch 157/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3633 - accuracy: 0.5100 - val_loss: 1.4251 - val_accuracy: 0.4960\n",
            "Epoch 158/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3650 - accuracy: 0.5071 - val_loss: 1.4180 - val_accuracy: 0.4848\n",
            "Epoch 159/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3617 - accuracy: 0.5180 - val_loss: 1.4199 - val_accuracy: 0.4926\n",
            "Epoch 160/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3529 - accuracy: 0.5158 - val_loss: 1.4157 - val_accuracy: 0.4840\n",
            "Epoch 161/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3511 - accuracy: 0.5179 - val_loss: 1.4182 - val_accuracy: 0.4916\n",
            "Epoch 162/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3645 - accuracy: 0.5095 - val_loss: 1.4404 - val_accuracy: 0.4914\n",
            "Epoch 163/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3403 - accuracy: 0.5189 - val_loss: 1.4278 - val_accuracy: 0.4800\n",
            "Epoch 164/200\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3506 - accuracy: 0.5155 - val_loss: 1.4197 - val_accuracy: 0.4884\n",
            "Epoch 165/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3610 - accuracy: 0.5134 - val_loss: 1.4408 - val_accuracy: 0.4902\n",
            "Epoch 166/200\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3564 - accuracy: 0.5160 - val_loss: 1.4037 - val_accuracy: 0.4916\n",
            "Epoch 167/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3610 - accuracy: 0.5094 - val_loss: 1.4214 - val_accuracy: 0.4910\n",
            "Epoch 168/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3471 - accuracy: 0.5139 - val_loss: 1.4024 - val_accuracy: 0.4954\n",
            "Epoch 169/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3515 - accuracy: 0.5159 - val_loss: 1.4167 - val_accuracy: 0.4896\n",
            "Epoch 170/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3499 - accuracy: 0.5131 - val_loss: 1.4146 - val_accuracy: 0.4872\n",
            "Epoch 171/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3468 - accuracy: 0.5122 - val_loss: 1.4219 - val_accuracy: 0.4870\n",
            "Epoch 172/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3630 - accuracy: 0.5139 - val_loss: 1.4331 - val_accuracy: 0.4904\n",
            "Epoch 173/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3606 - accuracy: 0.5173 - val_loss: 1.4037 - val_accuracy: 0.4910\n",
            "Epoch 174/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3526 - accuracy: 0.5132 - val_loss: 1.4126 - val_accuracy: 0.4936\n",
            "Epoch 175/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3544 - accuracy: 0.5169 - val_loss: 1.4217 - val_accuracy: 0.4970\n",
            "Epoch 176/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3440 - accuracy: 0.5178 - val_loss: 1.4270 - val_accuracy: 0.4816\n",
            "Epoch 177/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3480 - accuracy: 0.5146 - val_loss: 1.4050 - val_accuracy: 0.5008\n",
            "Epoch 178/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3583 - accuracy: 0.5158 - val_loss: 1.4330 - val_accuracy: 0.4976\n",
            "Epoch 179/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3514 - accuracy: 0.5148 - val_loss: 1.4519 - val_accuracy: 0.4954\n",
            "Epoch 180/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3462 - accuracy: 0.5197 - val_loss: 1.4304 - val_accuracy: 0.4898\n",
            "Epoch 181/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3515 - accuracy: 0.5153 - val_loss: 1.4135 - val_accuracy: 0.4916\n",
            "Epoch 182/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3501 - accuracy: 0.5127 - val_loss: 1.4178 - val_accuracy: 0.4918\n",
            "Epoch 183/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3565 - accuracy: 0.5117 - val_loss: 1.4129 - val_accuracy: 0.4948\n",
            "Epoch 184/200\n",
            "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3657 - accuracy: 0.5107 - val_loss: 1.4190 - val_accuracy: 0.4854\n",
            "Epoch 185/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3440 - accuracy: 0.5196 - val_loss: 1.4165 - val_accuracy: 0.4820\n",
            "Epoch 186/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3503 - accuracy: 0.5151 - val_loss: 1.4131 - val_accuracy: 0.4938\n",
            "Epoch 187/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3419 - accuracy: 0.5180 - val_loss: 1.4018 - val_accuracy: 0.4976\n",
            "Epoch 188/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3564 - accuracy: 0.5167 - val_loss: 1.4161 - val_accuracy: 0.4932\n",
            "Epoch 189/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3534 - accuracy: 0.5166 - val_loss: 1.4146 - val_accuracy: 0.4966\n",
            "Epoch 190/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3536 - accuracy: 0.5154 - val_loss: 1.4054 - val_accuracy: 0.5030\n",
            "Epoch 191/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3540 - accuracy: 0.5134 - val_loss: 1.4169 - val_accuracy: 0.4854\n",
            "Epoch 192/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3496 - accuracy: 0.5156 - val_loss: 1.4090 - val_accuracy: 0.5004\n",
            "Epoch 193/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3458 - accuracy: 0.5168 - val_loss: 1.4175 - val_accuracy: 0.4988\n",
            "Epoch 194/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3475 - accuracy: 0.5239 - val_loss: 1.4333 - val_accuracy: 0.4938\n",
            "Epoch 195/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3459 - accuracy: 0.5153 - val_loss: 1.4064 - val_accuracy: 0.4904\n",
            "Epoch 196/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3430 - accuracy: 0.5184 - val_loss: 1.4080 - val_accuracy: 0.4948\n",
            "Epoch 197/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3561 - accuracy: 0.5165 - val_loss: 1.3991 - val_accuracy: 0.4960\n",
            "Epoch 198/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3496 - accuracy: 0.5146 - val_loss: 1.4066 - val_accuracy: 0.4952\n",
            "Epoch 199/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3482 - accuracy: 0.5200 - val_loss: 1.4151 - val_accuracy: 0.4856\n",
            "Epoch 200/200\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3500 - accuracy: 0.5202 - val_loss: 1.4257 - val_accuracy: 0.4932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac1b732d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}